{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Способ 1: только инструментами yolo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7672473aea2d42f9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@172.828] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=1, value=0, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 2.4ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.6ms\n",
      "Speed: 2.1ms preprocess, 4.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.6ms\n",
      "Speed: 1.2ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.8ms\n",
      "Speed: 1.9ms preprocess, 4.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.4ms\n",
      "Speed: 1.7ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 2.1ms preprocess, 3.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 2.9ms\n",
      "Speed: 1.1ms preprocess, 2.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.0ms preprocess, 3.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.2ms\n",
      "Speed: 1.4ms preprocess, 4.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 6.0ms\n",
      "Speed: 4.0ms preprocess, 6.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 6.8ms\n",
      "Speed: 3.1ms preprocess, 6.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 3.1ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.2ms preprocess, 3.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.7ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.6ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 0.9ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 2.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.4ms\n",
      "Speed: 0.8ms preprocess, 5.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.7ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 2.7ms preprocess, 3.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.5ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.7ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.3ms\n",
      "Speed: 1.3ms preprocess, 4.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.1ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 2.4ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.1ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 2.2ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.5ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.4ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.8ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.3ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.8ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.5ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.7ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.5ms preprocess, 3.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.8ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.1ms preprocess, 3.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.6ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.1ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.8ms preprocess, 3.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.9ms\n",
      "Speed: 1.8ms preprocess, 13.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 face, 4.4ms\n",
      "Speed: 1.5ms preprocess, 4.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.0ms\n",
      "Speed: 1.3ms preprocess, 3.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.2ms\n",
      "Speed: 1.5ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.9ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.5ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.1ms\n",
      "Speed: 2.1ms preprocess, 5.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 face, 5.1ms\n",
      "Speed: 1.6ms preprocess, 5.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.4ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 face, 3.0ms\n",
      "Speed: 1.3ms preprocess, 3.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.9ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 2.0ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.7ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.8ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.2ms preprocess, 3.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.5ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 0.9ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.2ms preprocess, 3.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.8ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.1ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.7ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.1ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 2.6ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.7ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.5ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 2.1ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.6ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 0.9ms preprocess, 3.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.7ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.0ms preprocess, 3.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.7ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.0ms preprocess, 3.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.3ms preprocess, 3.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.4ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.5ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.1ms preprocess, 3.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.7ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.7ms preprocess, 3.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 1.2ms preprocess, 3.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.6ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.4ms preprocess, 3.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.7ms preprocess, 3.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.2ms preprocess, 3.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.1ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.2ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 1.1ms preprocess, 3.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 1.2ms preprocess, 3.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.5ms\n",
      "Speed: 1.2ms preprocess, 4.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.4ms preprocess, 3.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.5ms\n",
      "Speed: 1.2ms preprocess, 4.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.1ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.1ms preprocess, 3.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.7ms preprocess, 3.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.4ms\n",
      "Speed: 1.2ms preprocess, 4.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.1ms\n",
      "Speed: 1.4ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.1ms\n",
      "Speed: 2.3ms preprocess, 5.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.3ms\n",
      "Speed: 1.5ms preprocess, 5.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.3ms\n",
      "Speed: 1.4ms preprocess, 5.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 5.4ms\n",
      "Speed: 1.8ms preprocess, 5.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.6ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.8ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 2.6ms preprocess, 3.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.1ms\n",
      "Speed: 1.0ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.3ms\n",
      "Speed: 1.3ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 2.1ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.4ms\n",
      "Speed: 1.0ms preprocess, 4.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 2.1ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.8ms\n",
      "Speed: 1.9ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.2ms\n",
      "Speed: 1.5ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.3ms\n",
      "Speed: 2.1ms preprocess, 3.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.2ms\n",
      "Speed: 1.4ms preprocess, 3.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.0ms\n",
      "Speed: 3.4ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.2ms\n",
      "Speed: 1.5ms preprocess, 4.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.5ms\n",
      "Speed: 2.0ms preprocess, 3.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.1ms\n",
      "Speed: 1.5ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.4ms\n",
      "Speed: 1.9ms preprocess, 3.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.7ms\n",
      "Speed: 1.8ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 3.1ms\n",
      "Speed: 2.6ms preprocess, 3.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 25\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     24\u001B[0m start \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mnow()\n\u001B[0;32m---> 25\u001B[0m success, frame \u001B[38;5;241m=\u001B[39m \u001B[43mcap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# Run YOLOv8 tracking on the frame, persisting tracks between frames\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtrack(frame, persist\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, tracker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../cfg/bytetrack.yaml\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# print(cv2.getBuildInformation())\n",
    "\n",
    "model = YOLO('../../models/yolov8n-face.pt')\n",
    "model.to(\"cuda\")\n",
    "video_path = \"rtspsrc location=rtsp://127.0.0.1:18554/test user-id=user user-pw=pass latency=0 ! rtpjitterbuffer drop-on-latency=true ! decodebin ! videoconvert ! appsink\"\n",
    "cap = cv2.VideoCapture(video_path, cv2.CAP_GSTREAMER)\n",
    "\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "while cap.isOpened():\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    start = datetime.datetime.now()\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, persist=True, tracker=\"../../cfg/bytetrack.yaml\")\n",
    "        if len(results) != 0 and results[0].boxes.id != None:\n",
    "\n",
    "            boxes = results[0].boxes.xywh.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            frame = results[0].plot()\n",
    "\n",
    "            for (x, y, w, h), track_id in zip(boxes, track_ids):\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))\n",
    "                if len(track) > 30:\n",
    "                    track.pop(0)\n",
    "\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "        end = datetime.datetime.now()\n",
    "        fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "        cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 8)\n",
    "\n",
    "        cv2.imshow(\"YOLOv8 Tracking\", frame)\n",
    "\n",
    "    else:\n",
    "        print(\"no frame\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T17:28:03.267492Z",
     "start_time": "2024-03-10T17:27:56.239031Z"
    }
   },
   "id": "6515a6475a9d1952",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Способ 2: с помощью deepsort_tracker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e441898c0acd126"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3843.815] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=1, value=0, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 face, 8.9ms\n",
      "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 48\u001B[0m\n\u001B[1;32m     41\u001B[0m results \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m######################################\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# DETECTION\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m######################################\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# loop over the detections\u001B[39;00m\n\u001B[0;32m---> 48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdetections\u001B[49m\u001B[38;5;241m.\u001B[39mboxes\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mtolist():\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;66;03m# extract the confidence (i.e., probability) associated with the prediction\u001B[39;00m\n\u001B[1;32m     50\u001B[0m     confidence \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m4\u001B[39m]\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# filter out weak detections by ensuring the \u001B[39;00m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;66;03m# confidence is greater than the minimum confidence\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[3], line 48\u001B[0m\n\u001B[1;32m     41\u001B[0m results \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m######################################\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# DETECTION\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m######################################\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# loop over the detections\u001B[39;00m\n\u001B[0;32m---> 48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdetections\u001B[49m\u001B[38;5;241m.\u001B[39mboxes\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mtolist():\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;66;03m# extract the confidence (i.e., probability) associated with the prediction\u001B[39;00m\n\u001B[1;32m     50\u001B[0m     confidence \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m4\u001B[39m]\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# filter out weak detections by ensuring the \u001B[39;00m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;66;03m# confidence is greater than the minimum confidence\u001B[39;00m\n",
      "File \u001B[0;32m/snap/pycharm-professional/368/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 755\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    756\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m/snap/pycharm-professional/368/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/368/plugins/python/helpers/pydev/pydevd.py:1184\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1181\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1184\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/368/plugins/python/helpers/pydev/pydevd.py:1199\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1196\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1199\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1203\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('../../models/yolov8n-face.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"rtspsrc location=rtsp://127.0.0.1:18554/test user-id=user user-pw=pass latency=0 ! rtpjitterbuffer drop-on-latency=true ! decodebin ! videoconvert ! appsink\"\n",
    "cap = cv2.VideoCapture(video_path, cv2.CAP_GSTREAMER)\n",
    "\n",
    "FPS = 10  # Задайте желаемое значение FPS\n",
    "CONFIDENCE_THRESHOLD = 0.4\n",
    "GREEN = (0, 255, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "tracker = DeepSort(max_age=50)\n",
    "\n",
    "while cap.isOpened():\n",
    "    start = datetime.datetime.now()\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        continue\n",
    "    \n",
    "    # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "    detections = model.track(frame, persist=True)[0]\n",
    "\n",
    "    if detections.boxes.id == None:\n",
    "        continue\n",
    "        \n",
    "    # initialize the list of bounding boxes and confidences\n",
    "    results = []\n",
    "\n",
    "    ######################################\n",
    "    # DETECTION\n",
    "    ######################################\n",
    "\n",
    "    # loop over the detections\n",
    "    for data in detections.boxes.data.tolist():\n",
    "        # extract the confidence (i.e., probability) associated with the prediction\n",
    "        confidence = data[4]\n",
    "\n",
    "        # filter out weak detections by ensuring the \n",
    "        # confidence is greater than the minimum confidence\n",
    "        if float(confidence) < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        # if the confidence is greater than the minimum confidence,\n",
    "        # get the bounding box and the class id\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        class_id = int(data[5])\n",
    "        # add the bounding box (x, y, w, h), confidence and class id to the results list\n",
    "        results.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # TRACKING\n",
    "    ######################################\n",
    "\n",
    "    # update the tracker with the new detections\n",
    "    tracks = tracker.update_tracks(results, frame=frame)\n",
    "    # loop over the tracks\n",
    "    for track in tracks:\n",
    "        # if the track is not confirmed, ignore it\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        # get the track id and the bounding box\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "\n",
    "        xmin, ymin, xmax, ymax = int(ltrb[0]), int(\n",
    "            ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "        # draw the bounding box and the track id\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.rectangle(frame, (xmin, ymin - 20), (xmin + 20, ymin), GREEN, -1)\n",
    "        cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, 2)\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print(f\"Time to process 1 frame: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "    fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:43:23.496615013Z",
     "start_time": "2024-02-11T16:41:22.295066187Z"
    }
   },
   "id": "27d218b5c33301fe",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e137115c92051cb1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
