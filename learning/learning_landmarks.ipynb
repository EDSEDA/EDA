{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:30:50.860771113Z",
     "start_time": "2023-09-09T01:30:50.857301837Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas_profiling as pp\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data2/landmarks.csv')\n",
    "df.columns = [f'col{i}' for i in range(1405)]\n",
    "df.astype({'col1404':'string'})\n",
    "\n",
    "Y = df.iloc[:]['col1404']\n",
    "X = df.drop(columns=['col1404'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:31:44.249883006Z",
     "start_time": "2023-09-09T01:31:37.534904571Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['surprise', 'anger', 'contempt', 'sad', 'happy', 'disgust',\n       'neutral', 'fear'], dtype=object)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:33:45.613464803Z",
     "start_time": "2023-09-09T01:33:45.599133534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  -----------------------------\nH2O_cluster_uptime:         4 hours 29 mins\nH2O_cluster_timezone:       Europe/Moscow\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.42.0.3\nH2O_cluster_version_age:    17 days\nH2O_cluster_name:           H2O_from_python_vorkov_s0lk7n\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    7.731 Gb\nH2O_cluster_total_cores:    12\nH2O_cluster_allowed_cores:  8\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://localhost:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.8.10 final\n--------------------------  -----------------------------",
      "text/html": "\n<style>\n\n#h2o-table-18.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-18 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-18 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-18 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-18 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-18 .h2o-table th,\n#h2o-table-18 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-18 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-18\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>4 hours 29 mins</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Moscow</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.42.0.3</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>17 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_vorkov_s0lk7n</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>7.731 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>12</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.8.10 final</td></tr></tbody>\n  </table>\n</div>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(\n",
    "    nthreads=8,     # number of threads when launching a new H2O server\n",
    "    max_mem_size=8  # in gigabytes\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:33:52.253384477Z",
     "start_time": "2023-09-09T01:33:52.191290884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "col1404\nanger       3159\ncontempt    2857\ndisgust        1\nhappy       5038\nneutral     5117\nsurprise    4019\nName: col1404, dtype: int64"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.groupby(\"col1404\")[\"col1404\"].count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:28:16.450016916Z",
     "start_time": "2023-09-09T01:28:16.438195738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "04:36:41.602: Project: AutoML_2_20230909_43641\n",
      "04:36:41.602: 5-fold cross-validation will be used.\n",
      "04:36:41.603: Setting stopping tolerance adaptively based on the training frame: 0.006386420048890296\n",
      "04:36:41.603: Build control seed: 1\n",
      "04:36:41.604: training frame: Frame key: AutoML_2_20230909_43641_training_Key_Frame__upload_ae3d0a5414d9ea46ac6abb67ac324507.hex    cols: 1405    rows: 24518  chunks: 157    size: 290473276  checksum: 9014670398134974866\n",
      "04:36:41.604: validation frame: NULL\n",
      "04:36:41.604: leaderboard frame: NULL\n",
      "04:36:41.604: blending frame: NULL\n",
      "04:36:41.604: response column: col1404\n",
      "04:36:41.604: fold column: null\n",
      "04:36:41.604: weights column: null\n",
      "04:36:41.608: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
      "04:36:41.610: AutoML job created: 2023.09.09 04:36:41.598\n",
      "04:36:41.610: AutoML build started: 2023.09.09 04:36:41.610\n",
      "04:36:41.618: AutoML: starting XGBoost_1_AutoML_2_20230909_43641 model training\n",
      "████████████████████████\n",
      "04:58:26.24: New leader: XGBoost_1_AutoML_2_20230909_43641, mean_per_class_error: 0.5015266423843869\n",
      "04:58:26.29: AutoML: starting GLM_1_AutoML_2_20230909_43641 model training\n",
      "███████████████████████████████████████| (done) 100%\n",
      "\n",
      "05:36:42.358: GLM_1_AutoML_2_20230909_43641 [GLM def_1] cancelled\n",
      "05:36:42.358: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}]\n",
      "05:36:42.358: AutoML build stopped: 2023.09.09 05:36:42.358\n",
      "05:36:42.358: AutoML build done: built 1 models\n",
      "05:36:42.358: AutoML duration:  1:00:00.748\n"
     ]
    },
    {
     "data": {
      "text/plain": "Model Details\n=============\nH2OXGBoostEstimator : XGBoost\nModel Key: XGBoost_1_AutoML_2_20230909_43641\n\n\nModel Summary: \n    number_of_trees\n--  -----------------\n    40\n\nModelMetricsMultinomial: xgboost\n** Reported on train data. **\n\nMSE: 0.06863666117708979\nRMSE: 0.261985994238413\nLogLoss: 0.2527321984390449\nMean Per-Class Error: 0.01463669311478975\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    fear    happy    neutral    sad    surprise    Error       Rate\n-------  ----------  ---------  ------  -------  ---------  -----  ----------  ----------  ------------\n2666     2           1          7       0        2          9      10          0.0114943   31 / 2,697\n7        2381        5          4       5        22         0      3           0.0189534   46 / 2,427\n4        5           2072       5       12       13         5      9           0.0249412   53 / 2,125\n7        6           5          2597    2        1          7      5           0.0125475   33 / 2,630\n1        7           7          0       4254     19         3      7           0.0102373   44 / 4,298\n17       8           4          9       6        4308       13     8           0.0148639   65 / 4,373\n3        4           2          7       1        1          2550   6           0.00932401  24 / 2,574\n7        5           1          14      2        18         3      3344        0.0147319   50 / 3,394\n2712     2418        2097       2643    4282     4384       2590   3392        0.0141121   346 / 24,518\n\nTop-8 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.985888\n2    0.996615\n3    0.998369\n4    0.999062\n5    0.999225\n6    0.999674\n7    0.999959\n8    1\n\nModelMetricsMultinomial: xgboost\n** Reported on cross-validation data. **\n\nMSE: 0.38721573446474844\nRMSE: 0.6222666104369963\nLogLoss: 1.190552812564536\nMean Per-Class Error: 0.5015266423843869\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    fear    happy    neutral    sad    surprise    Error     Rate\n-------  ----------  ---------  ------  -------  ---------  -----  ----------  --------  ---------------\n1094     332         329        263     6        5          431    237         0.594364  1,603 / 2,697\n306      1258        161        94      19       64         276    249         0.481665  1,169 / 2,427\n520      276         495        242     21       24         294    253         0.767059  1,630 / 2,125\n301      131         180        921     2        4          317    774         0.64981   1,709 / 2,630\n3        13          13         10      3728     495        7      29          0.13262   570 / 4,298\n19       23          15         11      351      3806       36     112         0.129659  567 / 4,373\n460      337         227        333     2        7          771    437         0.700466  1,803 / 2,574\n231      214         151        677     50       222        344    1505        0.55657   1,889 / 3,394\n2934     2584        1571       2551    4179     4627       2476   3596        0.446203  10,940 / 24,518\n\nTop-8 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.553797\n2    0.740884\n3    0.842932\n4    0.914104\n5    0.961498\n6    0.98964\n7    0.998124\n8    1\n\nCross-Validation Metrics Summary: \n                         mean      sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  --------  -----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.553797  0.00758061   0.54894       0.562398      0.556688      0.557618      0.543341\nauc                      nan       0            nan           nan           nan           nan           nan\nerr                      0.446203  0.00758061   0.45106       0.437602      0.443312      0.442382      0.456659\nerr_count                2188      37.0742      2212          2146          2174          2169          2239\nlogloss                  1.19055   0.0066618    1.19322       1.18956       1.18316       1.1864        1.20043\nmax_per_class_error      0.766767  0.0139471    0.770936      0.765661      0.746341      0.785235      0.765661\nmean_per_class_accuracy  0.498671  0.00804925   0.49266       0.507236      0.500907      0.504437      0.488115\nmean_per_class_error     0.501329  0.00804925   0.50734       0.492764      0.499093      0.495563      0.511885\nmse                      0.387216  0.00355908   0.390823      0.385732      0.383948      0.384315      0.391261\npr_auc                   nan       0            nan           nan           nan           nan           nan\nr2                       0.921016  0.000692568  0.9202        0.9216        0.921802      0.920474      0.921006\nrmse                     0.622261  0.00285796   0.625158      0.621073      0.619636      0.619931      0.625509\n\nScoring History: \n    timestamp            duration           number_of_trees    training_rmse    training_logloss    training_classification_error    training_auc    training_pr_auc\n--  -------------------  -----------------  -----------------  ---------------  ------------------  -------------------------------  --------------  -----------------\n    2023-09-09 04:53:41  16 min 59.848 sec  0                  0.875            2.07944             0.821641                         nan             nan\n    2023-09-09 04:54:18  17 min 36.961 sec  5                  0.631161         1.06185             0.263929                         nan             nan\n    2023-09-09 04:54:53  18 min 11.937 sec  10                 0.522371         0.751528            0.171996                         nan             nan\n    2023-09-09 04:55:30  18 min 48.825 sec  15                 0.453192         0.585507            0.117057                         nan             nan\n    2023-09-09 04:56:04  19 min 23.021 sec  20                 0.40168          0.477862            0.0783914                        nan             nan\n    2023-09-09 04:56:39  19 min 57.863 sec  25                 0.358707         0.398988            0.0508198                        nan             nan\n    2023-09-09 04:57:15  20 min 33.736 sec  30                 0.323908         0.341556            0.035892                         nan             nan\n    2023-09-09 04:57:50  21 min  8.878 sec  35                 0.293123         0.295582            0.0242679                        nan             nan\n    2023-09-09 04:58:25  21 min 43.983 sec  40                 0.261986         0.252732            0.0141121                        nan             nan\n\nVariable Importances: \nvariable    relative_importance    scaled_importance       percentage\n----------  ---------------------  ----------------------  ----------------------\ncol568      9155.4169921875        1.0                     0.06874357355530089\ncol1195     3588.966064453125      0.3920046533670352      0.026947800722757015\ncol183      3087.619384765625      0.3372450853303954      0.02318343232957376\ncol918      2460.903564453125      0.2687920786735397      0.018477728031376706\ncol1240     2254.662109375         0.24626536522573994     0.016929161248518693\ncol520      1813.920654296875      0.19812540006039372     0.013619848012225093\ncol28       1794.205810546875      0.19597204715830055     0.01347181883860953\ncol571      1618.5386962890625     0.17678481468077248     0.01215281991146792\ncol873      1165.2108154296875     0.1272700977382008      0.00874900132525634\ncol400      986.4168090820312      0.10774133061593594     0.007406524086142585\n---         ---                    ---                     ---\ncol1121     4.060764312744141      0.00044353679534304903  3.0490304315147332e-05\ncol1062     3.75946044921875       0.0004106268947036244   2.82279601398434e-05\ncol1172     3.182528018951416      0.00034761147653538125  2.3896055105876733e-05\ncol237      3.085359811782837      0.00033699828357524686  2.3166466294965132e-05\ncol740      2.973966598510742      0.0003248313649775305   2.233006883140166e-05\ncol491      2.9122753143310547     0.00031809313729960715  2.186685898139197e-05\ncol743      2.8932557106018066     0.0003160157219568131   2.1724050026969696e-05\ncol758      1.935788631439209      0.00021143642426020093  1.453489538340093e-05\ncol374      1.5278366804122925     0.0001668778911671665   1.1471782586203608e-05\ncol485      0.9854693412780762     0.00010763784348861409  7.399410011193509e-06\n[1402 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OXGBoostEstimator : XGBoost\nModel Key: XGBoost_1_AutoML_2_20230909_43641\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-19.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-19 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-19 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-19 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-19 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-19 .h2o-table th,\n#h2o-table-19 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-19 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-19\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Model Summary: </caption>\n    <thead><tr><th></th>\n<th>number_of_trees</th></tr></thead>\n    <tbody><tr><td></td>\n<td>40.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomial: xgboost\n** Reported on train data. **\n\nMSE: 0.06863666117708979\nRMSE: 0.261985994238413\nLogLoss: 0.2527321984390449\nMean Per-Class Error: 0.01463669311478975\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-20.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-20 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-20 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-20 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-20 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-20 .h2o-table th,\n#h2o-table-20 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-20 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-20\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>fear</th>\n<th>happy</th>\n<th>neutral</th>\n<th>sad</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2666.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>7.0</td>\n<td>0.0</td>\n<td>2.0</td>\n<td>9.0</td>\n<td>10.0</td>\n<td>0.0114943</td>\n<td>31 / 2,697</td></tr>\n<tr><td>7.0</td>\n<td>2381.0</td>\n<td>5.0</td>\n<td>4.0</td>\n<td>5.0</td>\n<td>22.0</td>\n<td>0.0</td>\n<td>3.0</td>\n<td>0.0189534</td>\n<td>46 / 2,427</td></tr>\n<tr><td>4.0</td>\n<td>5.0</td>\n<td>2072.0</td>\n<td>5.0</td>\n<td>12.0</td>\n<td>13.0</td>\n<td>5.0</td>\n<td>9.0</td>\n<td>0.0249412</td>\n<td>53 / 2,125</td></tr>\n<tr><td>7.0</td>\n<td>6.0</td>\n<td>5.0</td>\n<td>2597.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>7.0</td>\n<td>5.0</td>\n<td>0.0125475</td>\n<td>33 / 2,630</td></tr>\n<tr><td>1.0</td>\n<td>7.0</td>\n<td>7.0</td>\n<td>0.0</td>\n<td>4254.0</td>\n<td>19.0</td>\n<td>3.0</td>\n<td>7.0</td>\n<td>0.0102373</td>\n<td>44 / 4,298</td></tr>\n<tr><td>17.0</td>\n<td>8.0</td>\n<td>4.0</td>\n<td>9.0</td>\n<td>6.0</td>\n<td>4308.0</td>\n<td>13.0</td>\n<td>8.0</td>\n<td>0.0148639</td>\n<td>65 / 4,373</td></tr>\n<tr><td>3.0</td>\n<td>4.0</td>\n<td>2.0</td>\n<td>7.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2550.0</td>\n<td>6.0</td>\n<td>0.0093240</td>\n<td>24 / 2,574</td></tr>\n<tr><td>7.0</td>\n<td>5.0</td>\n<td>1.0</td>\n<td>14.0</td>\n<td>2.0</td>\n<td>18.0</td>\n<td>3.0</td>\n<td>3344.0</td>\n<td>0.0147319</td>\n<td>50 / 3,394</td></tr>\n<tr><td>2712.0</td>\n<td>2418.0</td>\n<td>2097.0</td>\n<td>2643.0</td>\n<td>4282.0</td>\n<td>4384.0</td>\n<td>2590.0</td>\n<td>3392.0</td>\n<td>0.0141121</td>\n<td>346 / 24,518</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-21.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-21 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-21 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-21 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-21 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-21 .h2o-table th,\n#h2o-table-21 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-21 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-21\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-8 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.9858879</td></tr>\n<tr><td>2</td>\n<td>0.9966147</td></tr>\n<tr><td>3</td>\n<td>0.9983686</td></tr>\n<tr><td>4</td>\n<td>0.9990619</td></tr>\n<tr><td>5</td>\n<td>0.9992251</td></tr>\n<tr><td>6</td>\n<td>0.9996737</td></tr>\n<tr><td>7</td>\n<td>0.9999592</td></tr>\n<tr><td>8</td>\n<td>1.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomial: xgboost\n** Reported on cross-validation data. **\n\nMSE: 0.38721573446474844\nRMSE: 0.6222666104369963\nLogLoss: 1.190552812564536\nMean Per-Class Error: 0.5015266423843869\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-22.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-22 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-22 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-22 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-22 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-22 .h2o-table th,\n#h2o-table-22 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-22 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-22\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>fear</th>\n<th>happy</th>\n<th>neutral</th>\n<th>sad</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>1094.0</td>\n<td>332.0</td>\n<td>329.0</td>\n<td>263.0</td>\n<td>6.0</td>\n<td>5.0</td>\n<td>431.0</td>\n<td>237.0</td>\n<td>0.5943641</td>\n<td>1,603 / 2,697</td></tr>\n<tr><td>306.0</td>\n<td>1258.0</td>\n<td>161.0</td>\n<td>94.0</td>\n<td>19.0</td>\n<td>64.0</td>\n<td>276.0</td>\n<td>249.0</td>\n<td>0.4816646</td>\n<td>1,169 / 2,427</td></tr>\n<tr><td>520.0</td>\n<td>276.0</td>\n<td>495.0</td>\n<td>242.0</td>\n<td>21.0</td>\n<td>24.0</td>\n<td>294.0</td>\n<td>253.0</td>\n<td>0.7670588</td>\n<td>1,630 / 2,125</td></tr>\n<tr><td>301.0</td>\n<td>131.0</td>\n<td>180.0</td>\n<td>921.0</td>\n<td>2.0</td>\n<td>4.0</td>\n<td>317.0</td>\n<td>774.0</td>\n<td>0.6498099</td>\n<td>1,709 / 2,630</td></tr>\n<tr><td>3.0</td>\n<td>13.0</td>\n<td>13.0</td>\n<td>10.0</td>\n<td>3728.0</td>\n<td>495.0</td>\n<td>7.0</td>\n<td>29.0</td>\n<td>0.1326198</td>\n<td>570 / 4,298</td></tr>\n<tr><td>19.0</td>\n<td>23.0</td>\n<td>15.0</td>\n<td>11.0</td>\n<td>351.0</td>\n<td>3806.0</td>\n<td>36.0</td>\n<td>112.0</td>\n<td>0.1296593</td>\n<td>567 / 4,373</td></tr>\n<tr><td>460.0</td>\n<td>337.0</td>\n<td>227.0</td>\n<td>333.0</td>\n<td>2.0</td>\n<td>7.0</td>\n<td>771.0</td>\n<td>437.0</td>\n<td>0.7004662</td>\n<td>1,803 / 2,574</td></tr>\n<tr><td>231.0</td>\n<td>214.0</td>\n<td>151.0</td>\n<td>677.0</td>\n<td>50.0</td>\n<td>222.0</td>\n<td>344.0</td>\n<td>1505.0</td>\n<td>0.5565704</td>\n<td>1,889 / 3,394</td></tr>\n<tr><td>2934.0</td>\n<td>2584.0</td>\n<td>1571.0</td>\n<td>2551.0</td>\n<td>4179.0</td>\n<td>4627.0</td>\n<td>2476.0</td>\n<td>3596.0</td>\n<td>0.4462028</td>\n<td>10,940 / 24,518</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-23.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-23 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-23 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-23 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-23 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-23 .h2o-table th,\n#h2o-table-23 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-23 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-23\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-8 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.5537972</td></tr>\n<tr><td>2</td>\n<td>0.7408842</td></tr>\n<tr><td>3</td>\n<td>0.8429317</td></tr>\n<tr><td>4</td>\n<td>0.9141039</td></tr>\n<tr><td>5</td>\n<td>0.9614977</td></tr>\n<tr><td>6</td>\n<td>0.9896402</td></tr>\n<tr><td>7</td>\n<td>0.9981238</td></tr>\n<tr><td>8</td>\n<td>1.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-24.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-24 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-24 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-24 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-24 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-24 .h2o-table th,\n#h2o-table-24 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-24 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-24\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.5537969</td>\n<td>0.0075806</td>\n<td>0.5489397</td>\n<td>0.562398</td>\n<td>0.5566884</td>\n<td>0.5576178</td>\n<td>0.5433408</td></tr>\n<tr><td>auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>err</td>\n<td>0.4462030</td>\n<td>0.0075806</td>\n<td>0.4510603</td>\n<td>0.4376020</td>\n<td>0.4433116</td>\n<td>0.4423822</td>\n<td>0.4566592</td></tr>\n<tr><td>err_count</td>\n<td>2188.0</td>\n<td>37.07425</td>\n<td>2212.0</td>\n<td>2146.0</td>\n<td>2174.0</td>\n<td>2169.0</td>\n<td>2239.0</td></tr>\n<tr><td>logloss</td>\n<td>1.1905531</td>\n<td>0.0066618</td>\n<td>1.193218</td>\n<td>1.1895577</td>\n<td>1.1831642</td>\n<td>1.1863956</td>\n<td>1.2004297</td></tr>\n<tr><td>max_per_class_error</td>\n<td>0.7667670</td>\n<td>0.0139471</td>\n<td>0.7709360</td>\n<td>0.7656612</td>\n<td>0.7463415</td>\n<td>0.7852349</td>\n<td>0.7656612</td></tr>\n<tr><td>mean_per_class_accuracy</td>\n<td>0.4986709</td>\n<td>0.0080493</td>\n<td>0.4926602</td>\n<td>0.507236</td>\n<td>0.5009066</td>\n<td>0.5044369</td>\n<td>0.4881150</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.5013291</td>\n<td>0.0080493</td>\n<td>0.5073398</td>\n<td>0.492764</td>\n<td>0.4990934</td>\n<td>0.4955632</td>\n<td>0.5118850</td></tr>\n<tr><td>mse</td>\n<td>0.3872158</td>\n<td>0.0035591</td>\n<td>0.3908228</td>\n<td>0.3857317</td>\n<td>0.3839483</td>\n<td>0.3843150</td>\n<td>0.3912611</td></tr>\n<tr><td>pr_auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>r2</td>\n<td>0.9210162</td>\n<td>0.0006926</td>\n<td>0.9201997</td>\n<td>0.9216000</td>\n<td>0.9218017</td>\n<td>0.9204741</td>\n<td>0.9210055</td></tr>\n<tr><td>rmse</td>\n<td>0.6222614</td>\n<td>0.0028580</td>\n<td>0.6251582</td>\n<td>0.621073</td>\n<td>0.6196356</td>\n<td>0.6199315</td>\n<td>0.6255087</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-25.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-25 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-25 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-25 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-25 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-25 .h2o-table th,\n#h2o-table-25 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-25 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-25\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>number_of_trees</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_classification_error</th>\n<th>training_auc</th>\n<th>training_pr_auc</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-09-09 04:53:41</td>\n<td>16 min 59.848 sec</td>\n<td>0.0</td>\n<td>0.875</td>\n<td>2.0794415</td>\n<td>0.8216412</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:54:18</td>\n<td>17 min 36.961 sec</td>\n<td>5.0</td>\n<td>0.6311605</td>\n<td>1.0618469</td>\n<td>0.2639285</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:54:53</td>\n<td>18 min 11.937 sec</td>\n<td>10.0</td>\n<td>0.5223713</td>\n<td>0.7515279</td>\n<td>0.1719961</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:55:30</td>\n<td>18 min 48.825 sec</td>\n<td>15.0</td>\n<td>0.4531918</td>\n<td>0.5855074</td>\n<td>0.1170569</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:56:04</td>\n<td>19 min 23.021 sec</td>\n<td>20.0</td>\n<td>0.4016799</td>\n<td>0.4778622</td>\n<td>0.0783914</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:56:39</td>\n<td>19 min 57.863 sec</td>\n<td>25.0</td>\n<td>0.3587070</td>\n<td>0.3989880</td>\n<td>0.0508198</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:57:15</td>\n<td>20 min 33.736 sec</td>\n<td>30.0</td>\n<td>0.3239075</td>\n<td>0.3415555</td>\n<td>0.0358920</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:57:50</td>\n<td>21 min  8.878 sec</td>\n<td>35.0</td>\n<td>0.2931227</td>\n<td>0.2955822</td>\n<td>0.0242679</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td></td>\n<td>2023-09-09 04:58:25</td>\n<td>21 min 43.983 sec</td>\n<td>40.0</td>\n<td>0.2619860</td>\n<td>0.2527322</td>\n<td>0.0141121</td>\n<td>nan</td>\n<td>nan</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-26.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-26 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-26 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-26 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-26 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-26 .h2o-table th,\n#h2o-table-26 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-26 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-26\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>col568</td>\n<td>9155.4169922</td>\n<td>1.0</td>\n<td>0.0687436</td></tr>\n<tr><td>col1195</td>\n<td>3588.9660645</td>\n<td>0.3920047</td>\n<td>0.0269478</td></tr>\n<tr><td>col183</td>\n<td>3087.6193848</td>\n<td>0.3372451</td>\n<td>0.0231834</td></tr>\n<tr><td>col918</td>\n<td>2460.9035645</td>\n<td>0.2687921</td>\n<td>0.0184777</td></tr>\n<tr><td>col1240</td>\n<td>2254.6621094</td>\n<td>0.2462654</td>\n<td>0.0169292</td></tr>\n<tr><td>col520</td>\n<td>1813.9206543</td>\n<td>0.1981254</td>\n<td>0.0136198</td></tr>\n<tr><td>col28</td>\n<td>1794.2058105</td>\n<td>0.1959720</td>\n<td>0.0134718</td></tr>\n<tr><td>col571</td>\n<td>1618.5386963</td>\n<td>0.1767848</td>\n<td>0.0121528</td></tr>\n<tr><td>col873</td>\n<td>1165.2108154</td>\n<td>0.1272701</td>\n<td>0.0087490</td></tr>\n<tr><td>col400</td>\n<td>986.4168091</td>\n<td>0.1077413</td>\n<td>0.0074065</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>col1121</td>\n<td>4.0607643</td>\n<td>0.0004435</td>\n<td>0.0000305</td></tr>\n<tr><td>col1062</td>\n<td>3.7594604</td>\n<td>0.0004106</td>\n<td>0.0000282</td></tr>\n<tr><td>col1172</td>\n<td>3.1825280</td>\n<td>0.0003476</td>\n<td>0.0000239</td></tr>\n<tr><td>col237</td>\n<td>3.0853598</td>\n<td>0.0003370</td>\n<td>0.0000232</td></tr>\n<tr><td>col740</td>\n<td>2.9739666</td>\n<td>0.0003248</td>\n<td>0.0000223</td></tr>\n<tr><td>col491</td>\n<td>2.9122753</td>\n<td>0.0003181</td>\n<td>0.0000219</td></tr>\n<tr><td>col743</td>\n<td>2.8932557</td>\n<td>0.0003160</td>\n<td>0.0000217</td></tr>\n<tr><td>col758</td>\n<td>1.9357886</td>\n<td>0.0002114</td>\n<td>0.0000145</td></tr>\n<tr><td>col374</td>\n<td>1.5278367</td>\n<td>0.0001669</td>\n<td>0.0000115</td></tr>\n<tr><td>col485</td>\n<td>0.9854693</td>\n<td>0.0001076</td>\n<td>0.0000074</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[1402 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = xtrain\n",
    "train[\"col1404\"] = ytrain\n",
    "\n",
    "test = xtest\n",
    "test[\"col1404\"] = ytest\n",
    "\n",
    "train_h2o_frame = h2o.H2OFrame(train)\n",
    "test_h2o_frame = h2o.H2OFrame(test)\n",
    "\n",
    "x = train_h2o_frame.columns\n",
    "y = \"col1404\"\n",
    "x.remove(y)\n",
    "\n",
    "aml = H2OAutoML(max_models=8, seed=1, max_runtime_secs=60*60, verbosity='info')\n",
    "aml.train(x=x, y=y, training_frame=train_h2o_frame)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:36:44.159761384Z",
     "start_time": "2023-09-09T01:36:00.963441069Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'AUTO'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "model_id                             mean_per_class_error    logloss      rmse       mse\n---------------------------------  ----------------------  ---------  --------  --------\nXGBoost_1_AutoML_2_20230909_43641                0.501527    1.19055  0.622267  0.387216\n[1 row x 5 columns]\n",
      "text/html": "<table class='dataframe'>\n<thead>\n<tr><th>model_id                         </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n</thead>\n<tbody>\n<tr><td>XGBoost_1_AutoML_2_20230909_43641</td><td style=\"text-align: right;\">              0.501527</td><td style=\"text-align: right;\">  1.19055</td><td style=\"text-align: right;\">0.622267</td><td style=\"text-align: right;\">0.387216</td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[1 row x 5 columns]</pre>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:43:29.035987719Z",
     "start_time": "2023-09-09T02:43:28.995056774Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test_h2o_frame = test_h2o_frame.drop('col1404')\n",
    "pred = aml.predict(test_h2o_frame)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:43:42.472514603Z",
     "start_time": "2023-09-09T02:43:42.170318741Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "predict          anger     contempt      disgust         fear        happy      neutral          sad    surprise\n---------  -----------  -----------  -----------  -----------  -----------  -----------  -----------  ----------\nsurprise   0.0806781    0.00519591   0.0283022    0.252751     0.000609164  0.00137734   0.0142793    0.616807\nfear       0.0371579    0.00272076   0.0964443    0.67374      0.000719777  0.00147301   0.00763326   0.180111\nneutral    0.00535385   0.000793096  0.00281587   0.0123343    0.00806528   0.775466     0.00415289   0.191019\nneutral    0.000201495  0.00297931   0.000760255  0.000211083  0.0211697    0.972772     0.000222323  0.0016835\nhappy      0.000556266  0.0164881    0.000368954  0.00057013   0.969002     0.0100853    0.000967995  0.00196166\nfear       0.384633     0.0042521    0.100513     0.41946      0.000773854  0.00235564   0.0465746    0.0414379\nhappy      9.71884e-06  6.19527e-05  1.64672e-05  5.43716e-06  0.999676     0.000194392  9.64148e-06  2.5969e-05\nneutral    0.000286821  0.00545247   0.00136963   0.000255059  0.014101     0.975715     0.000183797  0.00263675\nanger      0.751265     0.00333145   0.0869584    0.0743677    0.00102531   0.00193492   0.0639569    0.0171607\nanger      0.36559      0.13635      0.331431     0.0458117    0.00330248   0.00221002   0.108022     0.00728327\n[4327 rows x 9 columns]\n",
      "text/html": "<table class='dataframe'>\n<thead>\n<tr><th>predict  </th><th style=\"text-align: right;\">      anger</th><th style=\"text-align: right;\">   contempt</th><th style=\"text-align: right;\">    disgust</th><th style=\"text-align: right;\">       fear</th><th style=\"text-align: right;\">      happy</th><th style=\"text-align: right;\">    neutral</th><th style=\"text-align: right;\">        sad</th><th style=\"text-align: right;\">  surprise</th></tr>\n</thead>\n<tbody>\n<tr><td>surprise </td><td style=\"text-align: right;\">0.0806781  </td><td style=\"text-align: right;\">0.00519591 </td><td style=\"text-align: right;\">0.0283022  </td><td style=\"text-align: right;\">0.252751   </td><td style=\"text-align: right;\">0.000609164</td><td style=\"text-align: right;\">0.00137734 </td><td style=\"text-align: right;\">0.0142793  </td><td style=\"text-align: right;\">0.616807  </td></tr>\n<tr><td>fear     </td><td style=\"text-align: right;\">0.0371579  </td><td style=\"text-align: right;\">0.00272076 </td><td style=\"text-align: right;\">0.0964443  </td><td style=\"text-align: right;\">0.67374    </td><td style=\"text-align: right;\">0.000719777</td><td style=\"text-align: right;\">0.00147301 </td><td style=\"text-align: right;\">0.00763326 </td><td style=\"text-align: right;\">0.180111  </td></tr>\n<tr><td>neutral  </td><td style=\"text-align: right;\">0.00535385 </td><td style=\"text-align: right;\">0.000793096</td><td style=\"text-align: right;\">0.00281587 </td><td style=\"text-align: right;\">0.0123343  </td><td style=\"text-align: right;\">0.00806528 </td><td style=\"text-align: right;\">0.775466   </td><td style=\"text-align: right;\">0.00415289 </td><td style=\"text-align: right;\">0.191019  </td></tr>\n<tr><td>neutral  </td><td style=\"text-align: right;\">0.000201495</td><td style=\"text-align: right;\">0.00297931 </td><td style=\"text-align: right;\">0.000760255</td><td style=\"text-align: right;\">0.000211083</td><td style=\"text-align: right;\">0.0211697  </td><td style=\"text-align: right;\">0.972772   </td><td style=\"text-align: right;\">0.000222323</td><td style=\"text-align: right;\">0.0016835 </td></tr>\n<tr><td>happy    </td><td style=\"text-align: right;\">0.000556266</td><td style=\"text-align: right;\">0.0164881  </td><td style=\"text-align: right;\">0.000368954</td><td style=\"text-align: right;\">0.00057013 </td><td style=\"text-align: right;\">0.969002   </td><td style=\"text-align: right;\">0.0100853  </td><td style=\"text-align: right;\">0.000967995</td><td style=\"text-align: right;\">0.00196166</td></tr>\n<tr><td>fear     </td><td style=\"text-align: right;\">0.384633   </td><td style=\"text-align: right;\">0.0042521  </td><td style=\"text-align: right;\">0.100513   </td><td style=\"text-align: right;\">0.41946    </td><td style=\"text-align: right;\">0.000773854</td><td style=\"text-align: right;\">0.00235564 </td><td style=\"text-align: right;\">0.0465746  </td><td style=\"text-align: right;\">0.0414379 </td></tr>\n<tr><td>happy    </td><td style=\"text-align: right;\">9.71884e-06</td><td style=\"text-align: right;\">6.19527e-05</td><td style=\"text-align: right;\">1.64672e-05</td><td style=\"text-align: right;\">5.43716e-06</td><td style=\"text-align: right;\">0.999676   </td><td style=\"text-align: right;\">0.000194392</td><td style=\"text-align: right;\">9.64148e-06</td><td style=\"text-align: right;\">2.5969e-05</td></tr>\n<tr><td>neutral  </td><td style=\"text-align: right;\">0.000286821</td><td style=\"text-align: right;\">0.00545247 </td><td style=\"text-align: right;\">0.00136963 </td><td style=\"text-align: right;\">0.000255059</td><td style=\"text-align: right;\">0.014101   </td><td style=\"text-align: right;\">0.975715   </td><td style=\"text-align: right;\">0.000183797</td><td style=\"text-align: right;\">0.00263675</td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.751265   </td><td style=\"text-align: right;\">0.00333145 </td><td style=\"text-align: right;\">0.0869584  </td><td style=\"text-align: right;\">0.0743677  </td><td style=\"text-align: right;\">0.00102531 </td><td style=\"text-align: right;\">0.00193492 </td><td style=\"text-align: right;\">0.0639569  </td><td style=\"text-align: right;\">0.0171607 </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.36559    </td><td style=\"text-align: right;\">0.13635    </td><td style=\"text-align: right;\">0.331431   </td><td style=\"text-align: right;\">0.0458117  </td><td style=\"text-align: right;\">0.00330248 </td><td style=\"text-align: right;\">0.00221002 </td><td style=\"text-align: right;\">0.108022   </td><td style=\"text-align: right;\">0.00728327</td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[4327 rows x 9 columns]</pre>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:43:51.645693487Z",
     "start_time": "2023-09-09T02:43:51.638462880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "best_model = aml.leader\n",
    "# aml.score(test_h2o_frame, test_h2o_frame.MEDV)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:44:00.175514669Z",
     "start_time": "2023-09-09T02:44:00.128291490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/vorkov/Workspace/Emotion-Decetion-Service/learning/XGBoost_1_AutoML_2_20230909_43641'"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(model=best_model, path=\"./\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:44:02.440786010Z",
     "start_time": "2023-09-09T02:44:02.426255945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n\n\nGLM Model: summary\n    family       link         regularization               lambda_search                                                                   number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n--  -----------  -----------  ---------------------------  ------------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  ---------------------------------------------------------------------------------------\n    multinomial  multinomial  Ridge ( lambda = 0.007732 )  nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062  8430                          8424                           205                     AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex\n\nModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2146     420         0          18       46         529         0.320671   1,013 / 3,159\n429      1948        0          47       84         349         0.318166   909 / 2,857\n1        0           0          0        0          0           1          1 / 1\n12       23          0          4407     553        43          0.125248   631 / 5,038\n46       38          0          316      4614       103         0.0982998  503 / 5,117\n383      360         0          104      325        2847        0.291615   1,172 / 4,019\n3017     2789        0          4892     5622       3871        0.20945    4,229 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.79055\n2    0.942301\n3    0.984349\n4    0.997524\n5    0.999851\n6    1\n\nModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2125     436         0          17       46         535         0.327319   1,034 / 3,159\n407      1972        0          46       84         348         0.309765   885 / 2,857\n1        0           0          0        0          0           1          1 / 1\n11       22          0          4405     554        46          0.125645   633 / 5,038\n46       38          0          316      4610       107         0.0990815  507 / 5,117\n389      361         0          100      323        2846        0.291864   1,173 / 4,019\n2979     2829        0          4884     5617       3882        0.209648   4,233 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.790352\n2    0.942152\n3    0.984102\n4    0.997573\n5    0.999852\n6    1\n\nCross-Validation Metrics Summary: \n                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.7906    0.00603916  0.791533      0.795691      0.789004      0.795691      0.78108\nauc                      nan       0           nan           nan           nan           nan           nan\nerr                      0.2094    0.00603916  0.208467      0.204309      0.210996      0.204309      0.21892\nerr_count                845.6     24.3783     842           825           852           825           884\nlogloss                  0.588093  0.0150114   0.601342      0.566701      0.589262      0.58057       0.602593\nmax_per_class_error      0.463815  0.299812    1             0.325949      0.34019       0.330696      0.322242\nmean_per_class_accuracy  0.774628  0.0748648   0.640994      0.812372      0.807228      0.812219      0.800326\nmean_per_class_error     0.225372  0.0748648   0.359006      0.187628      0.192772      0.187781      0.199674\nmse                      0.183476  0.00422378  0.186501      0.17799       0.185417      0.179982      0.187492\nnull_deviance            inf       nan         inf           12781.9       12780.7       12780.7       12780.2\npr_auc                   nan       0           nan           nan           nan           nan           nan\nr2                       0.939117  0.00141633  0.938089      0.94096       0.938478      0.940282      0.937774\nresidual_deviance        4749.72   121.538     4857.82       4576.68       4758.88       4688.68       4866.54\nrmse                     0.428319  0.00494095  0.431858      0.421888      0.430601      0.424242      0.433004\n\nScoring History: \n     timestamp            duration    iteration    lambda    predictors    deviance_train      deviance_xval       deviance_se            alpha    iterations    training_rmse       training_logloss    training_r2         training_classification_error    training_auc    training_pr_auc\n---  -------------------  ----------  -----------  --------  ------------  ------------------  ------------------  ---------------------  -------  ------------  ------------------  ------------------  ------------------  -------------------------------  --------------  -----------------\n     2023-09-09 00:44:00  0.000 sec   5            .22E2     8430          2.248140716119977   5.149931681186062   2.834724413204253      0.0\n     2023-09-09 00:44:00  0.677 sec   8            .16E2     8430          2.1535965161010697  5.0728719149317865  2.8539895652773546     0.0\n     2023-09-09 00:44:01  1.367 sec   12           .12E2     8430          2.062910412015913   2.12673455827772    0.0030129313526652754  0.0\n     2023-09-09 00:44:02  2.145 sec   16           .84E1     8430          1.9758453973316426  2.0371638351436987  0.003449756456666322   0.0\n     2023-09-09 00:44:03  3.117 sec   21           .61E1     8430          1.8925664407633036  1.9516812892231576  0.003938013706845999   0.0\n     2023-09-09 00:44:04  4.269 sec   26           .44E1     8430          1.8151123413826604  1.8703869552280885  0.004312489632431074   0.0\n     2023-09-09 00:44:05  5.408 sec   32           .32E1     8430          1.742629542726998   1.7921155853469783  0.004915638897145258   0.0\n     2023-09-09 00:44:06  6.448 sec   38           .24E1     8430          1.6742460670408088  1.722363487570209   0.005382304566046644   0.0\n     2023-09-09 00:44:07  7.583 sec   44           .17E1     8430          1.605945624848216   1.653229909846932   0.005549571198674038   0.0\n     2023-09-09 00:44:08  8.727 sec   50           .12E1     8430          1.546692054948466   1.5902172649935753  0.006997583138672032   0.0\n---  ---                  ---         ---          ---       ---           ---                 ---                 ---                    ---      ---           ---                 ---                 ---                 ---                              ---             ---\n     2023-09-09 00:44:32  32.010 sec  171          .38E-1    8430          1.2047304117119122  1.219371956915976   0.01171535704375587    0.0\n     2023-09-09 00:44:32  32.307 sec  172          .28E-1    8430          1.2045839758418027  1.2145364839233266  0.010951542185820255   0.0\n     2023-09-09 00:44:38  38.306 sec  201          .2E-1     8430          1.170156009321884   1.2028762552323793  0.007375434935290969   0.0\n     2023-09-09 00:44:38  38.682 sec  203          .15E-1    8430          1.1698353588678703  1.1946579373603106  0.007271888535685163   0.0\n     2023-09-09 00:44:39  38.964 sec  204          .11E-1    8430          1.1697612737323517  1.1861467449604013  0.01424862623234221    0.0\n     2023-09-09 00:44:39  39.151 sec  205          .77E-2    8430          1.1696957862297173  1.1762900748535214  0.01344541482508615    0.0\n     2023-09-09 00:44:39  39.433 sec  206          .56E-2    8430          1.1696321484590473  1.1763251144765063  0.013439865599289018   0.0\n     2023-09-09 00:44:39  39.627 sec  207          .41E-2    8430          1.1695627962171948  1.528804480722551   0.35997155430461053    0.0\n     2023-09-09 00:44:39  39.917 sec  208          .3E-2     8430          1.169494213685578   1.7391552026800745  0.24224461444307635    0.0\n     2023-09-09 00:44:40  40.108 sec  209          .22E-2    8430          1.1694212595229305  0.0                 0.0                    0.0      209           0.4280754520274582  0.5848479289901717  0.9391926917188472  0.2094497548412659               nan             nan\n[30 rows x 17 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance     percentage\n----------  ---------------------  --------------------  ----------------------\ncol874      0.2500748336315155     1.0                   0.002491267590981969\ncol919      0.24001291394233704    0.9597643651579724    0.0023910298578974404\ncol166      0.2380715012550354     0.9520010382405493    0.0023716893331498664\ncol862      0.2356162667274475     0.9421830389963484    0.002347230069824503\ncol44       0.23441898822784424    0.9373953581161225    0.002335302675611632\ncol196      0.23107394576072693    0.9240191921959395    0.002301979066963083\ncol877      0.23084664344787598    0.9231102550208142    0.002299714661236455\ncol322      0.22571641206741333    0.9025954702823307    0.0022486068428814988\ncol925      0.21996857225894928    0.8796109910966583    0.0021913463547906338\ncol184      0.21731959283351898    0.8690182441698181    0.002164956987672323\n---         ---                    ---                   ---\ncol0        0.011895542033016682   0.047567929408461496  0.0001185044409054182\ncol392      0.011644117534160614   0.0465625323630853    0.00011599972783020348\ncol36       0.01144136767834425    0.04575177562730311   0.00011397991585017895\ncol98       0.010843622498214245   0.04336151039569335   0.00010802512554481857\ncol740      0.010798311792314053   0.04318032180809258   0.00010757373628867297\ncol788      0.0101018650457263     0.04039536845443379   0.00010063567225630627\ncol92       0.010025384835898876   0.04008953916039088   9.98737696476843e-05\ncol39       0.00972403772175312    0.03888451141021835   9.687172306744555e-05\ncol743      0.00782020017504692    0.03127144007849251   7.790552519088302e-05\ncol1298     0.007329002022743225   0.029307235423547205  7.301216579196186e-05\n[1404 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-10.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-10 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-10 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-10 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-10 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-10 .h2o-table th,\n#h2o-table-10 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-10 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-10\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>GLM Model: summary</caption>\n    <thead><tr><th></th>\n<th>family</th>\n<th>link</th>\n<th>regularization</th>\n<th>lambda_search</th>\n<th>number_of_predictors_total</th>\n<th>number_of_active_predictors</th>\n<th>number_of_iterations</th>\n<th>training_frame</th></tr></thead>\n    <tbody><tr><td></td>\n<td>multinomial</td>\n<td>multinomial</td>\n<td>Ridge ( lambda = 0.007732 )</td>\n<td>nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062</td>\n<td>8430</td>\n<td>8424</td>\n<td>205</td>\n<td>AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-11.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-11 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-11 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-11 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-11 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-11 .h2o-table th,\n#h2o-table-11 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-11 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-11\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2146.0</td>\n<td>420.0</td>\n<td>0.0</td>\n<td>18.0</td>\n<td>46.0</td>\n<td>529.0</td>\n<td>0.3206711</td>\n<td>1,013 / 3,159</td></tr>\n<tr><td>429.0</td>\n<td>1948.0</td>\n<td>0.0</td>\n<td>47.0</td>\n<td>84.0</td>\n<td>349.0</td>\n<td>0.3181659</td>\n<td>909 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>12.0</td>\n<td>23.0</td>\n<td>0.0</td>\n<td>4407.0</td>\n<td>553.0</td>\n<td>43.0</td>\n<td>0.1252481</td>\n<td>631 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4614.0</td>\n<td>103.0</td>\n<td>0.0982998</td>\n<td>503 / 5,117</td></tr>\n<tr><td>383.0</td>\n<td>360.0</td>\n<td>0.0</td>\n<td>104.0</td>\n<td>325.0</td>\n<td>2847.0</td>\n<td>0.2916148</td>\n<td>1,172 / 4,019</td></tr>\n<tr><td>3017.0</td>\n<td>2789.0</td>\n<td>0.0</td>\n<td>4892.0</td>\n<td>5622.0</td>\n<td>3871.0</td>\n<td>0.2094498</td>\n<td>4,229 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-12.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-12 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-12 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-12 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-12 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-12 .h2o-table th,\n#h2o-table-12 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-12 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-12\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7905502</td></tr>\n<tr><td>2</td>\n<td>0.9423010</td></tr>\n<tr><td>3</td>\n<td>0.9843495</td></tr>\n<tr><td>4</td>\n<td>0.9975237</td></tr>\n<tr><td>5</td>\n<td>0.9998514</td></tr>\n<tr><td>6</td>\n<td>1.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-13.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-13 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-13 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-13 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-13 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-13 .h2o-table th,\n#h2o-table-13 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-13 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-13\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2125.0</td>\n<td>436.0</td>\n<td>0.0</td>\n<td>17.0</td>\n<td>46.0</td>\n<td>535.0</td>\n<td>0.3273188</td>\n<td>1,034 / 3,159</td></tr>\n<tr><td>407.0</td>\n<td>1972.0</td>\n<td>0.0</td>\n<td>46.0</td>\n<td>84.0</td>\n<td>348.0</td>\n<td>0.3097655</td>\n<td>885 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>11.0</td>\n<td>22.0</td>\n<td>0.0</td>\n<td>4405.0</td>\n<td>554.0</td>\n<td>46.0</td>\n<td>0.1256451</td>\n<td>633 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4610.0</td>\n<td>107.0</td>\n<td>0.0990815</td>\n<td>507 / 5,117</td></tr>\n<tr><td>389.0</td>\n<td>361.0</td>\n<td>0.0</td>\n<td>100.0</td>\n<td>323.0</td>\n<td>2846.0</td>\n<td>0.2918636</td>\n<td>1,173 / 4,019</td></tr>\n<tr><td>2979.0</td>\n<td>2829.0</td>\n<td>0.0</td>\n<td>4884.0</td>\n<td>5617.0</td>\n<td>3882.0</td>\n<td>0.2096479</td>\n<td>4,233 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-14.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-14 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-14 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-14 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-14 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-14 .h2o-table th,\n#h2o-table-14 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-14 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-14\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7903522</td></tr>\n<tr><td>2</td>\n<td>0.9421525</td></tr>\n<tr><td>3</td>\n<td>0.9841019</td></tr>\n<tr><td>4</td>\n<td>0.9975733</td></tr>\n<tr><td>5</td>\n<td>0.9998515</td></tr>\n<tr><td>6</td>\n<td>1.0000001</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-15.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-15 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-15 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-15 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-15 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-15 .h2o-table th,\n#h2o-table-15 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-15 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-15\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.7905997</td>\n<td>0.0060392</td>\n<td>0.7915326</td>\n<td>0.7956910</td>\n<td>0.7890044</td>\n<td>0.7956910</td>\n<td>0.7810798</td></tr>\n<tr><td>auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>err</td>\n<td>0.2094003</td>\n<td>0.0060392</td>\n<td>0.2084674</td>\n<td>0.2043091</td>\n<td>0.2109955</td>\n<td>0.2043091</td>\n<td>0.2189203</td></tr>\n<tr><td>err_count</td>\n<td>845.6</td>\n<td>24.37827</td>\n<td>842.0</td>\n<td>825.0</td>\n<td>852.0</td>\n<td>825.0</td>\n<td>884.0</td></tr>\n<tr><td>logloss</td>\n<td>0.5880934</td>\n<td>0.0150114</td>\n<td>0.6013420</td>\n<td>0.5667007</td>\n<td>0.5892617</td>\n<td>0.5805697</td>\n<td>0.6025928</td></tr>\n<tr><td>max_per_class_error</td>\n<td>0.4638154</td>\n<td>0.2998116</td>\n<td>1.0</td>\n<td>0.3259494</td>\n<td>0.3401899</td>\n<td>0.3306962</td>\n<td>0.3222417</td></tr>\n<tr><td>mean_per_class_accuracy</td>\n<td>0.7746276</td>\n<td>0.0748648</td>\n<td>0.6409936</td>\n<td>0.812372</td>\n<td>0.8072276</td>\n<td>0.8122187</td>\n<td>0.8003262</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.2253724</td>\n<td>0.0748648</td>\n<td>0.3590064</td>\n<td>0.1876280</td>\n<td>0.1927724</td>\n<td>0.1877813</td>\n<td>0.1996739</td></tr>\n<tr><td>mse</td>\n<td>0.1834765</td>\n<td>0.0042238</td>\n<td>0.1865014</td>\n<td>0.1779897</td>\n<td>0.1854174</td>\n<td>0.1799816</td>\n<td>0.1874921</td></tr>\n<tr><td>null_deviance</td>\n<td>inf</td>\n<td>nan</td>\n<td>inf</td>\n<td>12781.859</td>\n<td>12780.725</td>\n<td>12780.725</td>\n<td>12780.242</td></tr>\n<tr><td>pr_auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>r2</td>\n<td>0.9391168</td>\n<td>0.0014163</td>\n<td>0.9380893</td>\n<td>0.9409605</td>\n<td>0.9384785</td>\n<td>0.9402820</td>\n<td>0.9377737</td></tr>\n<tr><td>residual_deviance</td>\n<td>4749.718</td>\n<td>121.53792</td>\n<td>4857.817</td>\n<td>4576.675</td>\n<td>4758.8774</td>\n<td>4688.681</td>\n<td>4866.5396</td></tr>\n<tr><td>rmse</td>\n<td>0.4283187</td>\n<td>0.0049410</td>\n<td>0.4318581</td>\n<td>0.4218883</td>\n<td>0.4306012</td>\n<td>0.4242424</td>\n<td>0.4330036</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-16.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-16 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-16 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-16 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-16 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-16 .h2o-table th,\n#h2o-table-16 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-16 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-16\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>iteration</th>\n<th>lambda</th>\n<th>predictors</th>\n<th>deviance_train</th>\n<th>deviance_xval</th>\n<th>deviance_se</th>\n<th>alpha</th>\n<th>iterations</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_r2</th>\n<th>training_classification_error</th>\n<th>training_auc</th>\n<th>training_pr_auc</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.000 sec</td>\n<td>5</td>\n<td>.22E2</td>\n<td>8430</td>\n<td>2.2481407</td>\n<td>5.1499317</td>\n<td>2.8347244</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.677 sec</td>\n<td>8</td>\n<td>.16E2</td>\n<td>8430</td>\n<td>2.1535965</td>\n<td>5.0728719</td>\n<td>2.8539896</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:01</td>\n<td> 1.367 sec</td>\n<td>12</td>\n<td>.12E2</td>\n<td>8430</td>\n<td>2.0629104</td>\n<td>2.1267346</td>\n<td>0.0030129</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:02</td>\n<td> 2.145 sec</td>\n<td>16</td>\n<td>.84E1</td>\n<td>8430</td>\n<td>1.9758454</td>\n<td>2.0371638</td>\n<td>0.0034498</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:03</td>\n<td> 3.117 sec</td>\n<td>21</td>\n<td>.61E1</td>\n<td>8430</td>\n<td>1.8925664</td>\n<td>1.9516813</td>\n<td>0.0039380</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:04</td>\n<td> 4.269 sec</td>\n<td>26</td>\n<td>.44E1</td>\n<td>8430</td>\n<td>1.8151123</td>\n<td>1.8703870</td>\n<td>0.0043125</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:05</td>\n<td> 5.408 sec</td>\n<td>32</td>\n<td>.32E1</td>\n<td>8430</td>\n<td>1.7426295</td>\n<td>1.7921156</td>\n<td>0.0049156</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:06</td>\n<td> 6.448 sec</td>\n<td>38</td>\n<td>.24E1</td>\n<td>8430</td>\n<td>1.6742461</td>\n<td>1.7223635</td>\n<td>0.0053823</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:07</td>\n<td> 7.583 sec</td>\n<td>44</td>\n<td>.17E1</td>\n<td>8430</td>\n<td>1.6059456</td>\n<td>1.6532299</td>\n<td>0.0055496</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:08</td>\n<td> 8.727 sec</td>\n<td>50</td>\n<td>.12E1</td>\n<td>8430</td>\n<td>1.5466921</td>\n<td>1.5902173</td>\n<td>0.0069976</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.010 sec</td>\n<td>171</td>\n<td>.38E-1</td>\n<td>8430</td>\n<td>1.2047304</td>\n<td>1.2193720</td>\n<td>0.0117154</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.307 sec</td>\n<td>172</td>\n<td>.28E-1</td>\n<td>8430</td>\n<td>1.2045840</td>\n<td>1.2145365</td>\n<td>0.0109515</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.306 sec</td>\n<td>201</td>\n<td>.2E-1</td>\n<td>8430</td>\n<td>1.1701560</td>\n<td>1.2028763</td>\n<td>0.0073754</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.682 sec</td>\n<td>203</td>\n<td>.15E-1</td>\n<td>8430</td>\n<td>1.1698354</td>\n<td>1.1946579</td>\n<td>0.0072719</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>38.964 sec</td>\n<td>204</td>\n<td>.11E-1</td>\n<td>8430</td>\n<td>1.1697613</td>\n<td>1.1861467</td>\n<td>0.0142486</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.151 sec</td>\n<td>205</td>\n<td>.77E-2</td>\n<td>8430</td>\n<td>1.1696958</td>\n<td>1.1762901</td>\n<td>0.0134454</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.433 sec</td>\n<td>206</td>\n<td>.56E-2</td>\n<td>8430</td>\n<td>1.1696321</td>\n<td>1.1763251</td>\n<td>0.0134399</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.627 sec</td>\n<td>207</td>\n<td>.41E-2</td>\n<td>8430</td>\n<td>1.1695628</td>\n<td>1.5288045</td>\n<td>0.3599716</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.917 sec</td>\n<td>208</td>\n<td>.3E-2</td>\n<td>8430</td>\n<td>1.1694942</td>\n<td>1.7391552</td>\n<td>0.2422446</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:40</td>\n<td>40.108 sec</td>\n<td>209</td>\n<td>.22E-2</td>\n<td>8430</td>\n<td>1.1694213</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>209</td>\n<td>0.4280755</td>\n<td>0.5848479</td>\n<td>0.9391927</td>\n<td>0.2094498</td>\n<td>nan</td>\n<td>nan</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 17 columns]</pre></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-17.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-17 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-17 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-17 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-17 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-17 .h2o-table th,\n#h2o-table-17 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-17 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-17\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>col874</td>\n<td>0.2500748</td>\n<td>1.0</td>\n<td>0.0024913</td></tr>\n<tr><td>col919</td>\n<td>0.2400129</td>\n<td>0.9597644</td>\n<td>0.0023910</td></tr>\n<tr><td>col166</td>\n<td>0.2380715</td>\n<td>0.9520010</td>\n<td>0.0023717</td></tr>\n<tr><td>col862</td>\n<td>0.2356163</td>\n<td>0.9421830</td>\n<td>0.0023472</td></tr>\n<tr><td>col44</td>\n<td>0.2344190</td>\n<td>0.9373954</td>\n<td>0.0023353</td></tr>\n<tr><td>col196</td>\n<td>0.2310739</td>\n<td>0.9240192</td>\n<td>0.0023020</td></tr>\n<tr><td>col877</td>\n<td>0.2308466</td>\n<td>0.9231103</td>\n<td>0.0022997</td></tr>\n<tr><td>col322</td>\n<td>0.2257164</td>\n<td>0.9025955</td>\n<td>0.0022486</td></tr>\n<tr><td>col925</td>\n<td>0.2199686</td>\n<td>0.8796110</td>\n<td>0.0021913</td></tr>\n<tr><td>col184</td>\n<td>0.2173196</td>\n<td>0.8690182</td>\n<td>0.0021650</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>col0</td>\n<td>0.0118955</td>\n<td>0.0475679</td>\n<td>0.0001185</td></tr>\n<tr><td>col392</td>\n<td>0.0116441</td>\n<td>0.0465625</td>\n<td>0.0001160</td></tr>\n<tr><td>col36</td>\n<td>0.0114414</td>\n<td>0.0457518</td>\n<td>0.0001140</td></tr>\n<tr><td>col98</td>\n<td>0.0108436</td>\n<td>0.0433615</td>\n<td>0.0001080</td></tr>\n<tr><td>col740</td>\n<td>0.0107983</td>\n<td>0.0431803</td>\n<td>0.0001076</td></tr>\n<tr><td>col788</td>\n<td>0.0101019</td>\n<td>0.0403954</td>\n<td>0.0001006</td></tr>\n<tr><td>col92</td>\n<td>0.0100254</td>\n<td>0.0400895</td>\n<td>0.0000999</td></tr>\n<tr><td>col39</td>\n<td>0.0097240</td>\n<td>0.0388845</td>\n<td>0.0000969</td></tr>\n<tr><td>col743</td>\n<td>0.0078202</td>\n<td>0.0312714</td>\n<td>0.0000779</td></tr>\n<tr><td>col1298</td>\n<td>0.0073290</td>\n<td>0.0293072</td>\n<td>0.0000730</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[1404 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.load_model('/home/vorkov/Workspace/Emotion-Decetion-Service/learning/GLM_1_AutoML_1_20230909_00442')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T23:11:28.538100331Z",
     "start_time": "2023-09-08T23:11:28.417201700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.550724958244778"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn. metrics import f1_score\n",
    "\n",
    "pred = aml.predict(test_h2o_frame)\n",
    "pd=h2o.as_list(pred) \n",
    "f1_score(test['col1404'], pd[\"predict\"].tolist(), average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:44:39.107927016Z",
     "start_time": "2023-09-09T02:44:38.801389534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "10830    surprise\n28509        fear\n13902     neutral\n14910     neutral\n15942     neutral\n           ...   \n1854     contempt\n23327         sad\n19950       anger\n17097       anger\n12642     neutral\nName: col1404, Length: 4327, dtype: object"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['col1404']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:45:06.192020312Z",
     "start_time": "2023-09-09T02:45:06.147623149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "['surprise',\n 'fear',\n 'neutral',\n 'neutral',\n 'happy',\n 'fear',\n 'happy',\n 'neutral',\n 'anger',\n 'anger',\n 'neutral',\n 'contempt',\n 'surprise',\n 'surprise',\n 'happy',\n 'sad',\n 'fear',\n 'disgust',\n 'fear',\n 'neutral',\n 'anger',\n 'neutral',\n 'fear',\n 'neutral',\n 'happy',\n 'neutral',\n 'surprise',\n 'surprise',\n 'neutral',\n 'sad',\n 'surprise',\n 'disgust',\n 'neutral',\n 'anger',\n 'happy',\n 'sad',\n 'happy',\n 'fear',\n 'fear',\n 'disgust',\n 'happy',\n 'happy',\n 'happy',\n 'disgust',\n 'disgust',\n 'fear',\n 'disgust',\n 'anger',\n 'neutral',\n 'contempt',\n 'surprise',\n 'surprise',\n 'neutral',\n 'fear',\n 'contempt',\n 'happy',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'disgust',\n 'sad',\n 'disgust',\n 'neutral',\n 'fear',\n 'happy',\n 'fear',\n 'neutral',\n 'anger',\n 'contempt',\n 'anger',\n 'sad',\n 'happy',\n 'surprise',\n 'disgust',\n 'neutral',\n 'anger',\n 'happy',\n 'neutral',\n 'neutral',\n 'neutral',\n 'fear',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'neutral',\n 'neutral',\n 'surprise',\n 'contempt',\n 'neutral',\n 'contempt',\n 'neutral',\n 'surprise',\n 'happy',\n 'happy',\n 'neutral',\n 'sad',\n 'anger',\n 'contempt',\n 'happy',\n 'neutral',\n 'surprise',\n 'happy',\n 'surprise',\n 'neutral',\n 'anger',\n 'anger',\n 'sad',\n 'happy',\n 'sad',\n 'fear',\n 'neutral',\n 'happy',\n 'neutral',\n 'happy',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'sad',\n 'surprise',\n 'happy',\n 'happy',\n 'neutral',\n 'surprise',\n 'anger',\n 'happy',\n 'anger',\n 'happy',\n 'anger',\n 'disgust',\n 'fear',\n 'neutral',\n 'contempt',\n 'contempt',\n 'fear',\n 'surprise',\n 'sad',\n 'fear',\n 'disgust',\n 'disgust',\n 'neutral',\n 'surprise',\n 'disgust',\n 'disgust',\n 'surprise',\n 'surprise',\n 'neutral',\n 'contempt',\n 'sad',\n 'neutral',\n 'happy',\n 'neutral',\n 'neutral',\n 'sad',\n 'contempt',\n 'surprise',\n 'happy',\n 'neutral',\n 'contempt',\n 'disgust',\n 'happy',\n 'neutral',\n 'fear',\n 'happy',\n 'neutral',\n 'anger',\n 'fear',\n 'sad',\n 'fear',\n 'neutral',\n 'anger',\n 'fear',\n 'happy',\n 'happy',\n 'fear',\n 'sad',\n 'contempt',\n 'disgust',\n 'anger',\n 'contempt',\n 'happy',\n 'neutral',\n 'anger',\n 'surprise',\n 'sad',\n 'disgust',\n 'neutral',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'disgust',\n 'neutral',\n 'contempt',\n 'sad',\n 'disgust',\n 'anger',\n 'fear',\n 'sad',\n 'surprise',\n 'neutral',\n 'neutral',\n 'neutral',\n 'disgust',\n 'anger',\n 'neutral',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'sad',\n 'neutral',\n 'fear',\n 'contempt',\n 'surprise',\n 'happy',\n 'fear',\n 'neutral',\n 'surprise',\n 'sad',\n 'surprise',\n 'disgust',\n 'sad',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'neutral',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'surprise',\n 'contempt',\n 'happy',\n 'contempt',\n 'disgust',\n 'neutral',\n 'surprise',\n 'surprise',\n 'surprise',\n 'disgust',\n 'happy',\n 'disgust',\n 'neutral',\n 'anger',\n 'neutral',\n 'sad',\n 'contempt',\n 'happy',\n 'happy',\n 'sad',\n 'anger',\n 'surprise',\n 'surprise',\n 'sad',\n 'happy',\n 'happy',\n 'neutral',\n 'neutral',\n 'anger',\n 'happy',\n 'surprise',\n 'anger',\n 'happy',\n 'surprise',\n 'sad',\n 'contempt',\n 'disgust',\n 'fear',\n 'disgust',\n 'surprise',\n 'happy',\n 'happy',\n 'disgust',\n 'neutral',\n 'surprise',\n 'surprise',\n 'surprise',\n 'sad',\n 'sad',\n 'fear',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'fear',\n 'surprise',\n 'happy',\n 'surprise',\n 'neutral',\n 'happy',\n 'neutral',\n 'fear',\n 'disgust',\n 'neutral',\n 'neutral',\n 'sad',\n 'fear',\n 'contempt',\n 'contempt',\n 'surprise',\n 'surprise',\n 'happy',\n 'contempt',\n 'fear',\n 'happy',\n 'happy',\n 'surprise',\n 'anger',\n 'fear',\n 'contempt',\n 'surprise',\n 'fear',\n 'neutral',\n 'surprise',\n 'contempt',\n 'contempt',\n 'anger',\n 'contempt',\n 'contempt',\n 'neutral',\n 'neutral',\n 'happy',\n 'sad',\n 'neutral',\n 'disgust',\n 'happy',\n 'neutral',\n 'neutral',\n 'neutral',\n 'disgust',\n 'surprise',\n 'neutral',\n 'neutral',\n 'neutral',\n 'neutral',\n 'happy',\n 'contempt',\n 'happy',\n 'disgust',\n 'happy',\n 'disgust',\n 'sad',\n 'disgust',\n 'surprise',\n 'neutral',\n 'anger',\n 'anger',\n 'neutral',\n 'sad',\n 'neutral',\n 'happy',\n 'surprise',\n 'disgust',\n 'happy',\n 'fear',\n 'happy',\n 'disgust',\n 'happy',\n 'anger',\n 'surprise',\n 'happy',\n 'disgust',\n 'sad',\n 'anger',\n 'anger',\n 'anger',\n 'fear',\n 'surprise',\n 'neutral',\n 'surprise',\n 'contempt',\n 'neutral',\n 'fear',\n 'sad',\n 'surprise',\n 'happy',\n 'happy',\n 'fear',\n 'happy',\n 'contempt',\n 'neutral',\n 'surprise',\n 'surprise',\n 'surprise',\n 'fear',\n 'surprise',\n 'happy',\n 'surprise',\n 'fear',\n 'anger',\n 'neutral',\n 'happy',\n 'surprise',\n 'fear',\n 'surprise',\n 'happy',\n 'happy',\n 'fear',\n 'contempt',\n 'fear',\n 'neutral',\n 'fear',\n 'fear',\n 'anger',\n 'neutral',\n 'surprise',\n 'anger',\n 'contempt',\n 'neutral',\n 'anger',\n 'happy',\n 'sad',\n 'anger',\n 'sad',\n 'anger',\n 'surprise',\n 'sad',\n 'contempt',\n 'anger',\n 'happy',\n 'disgust',\n 'surprise',\n 'neutral',\n 'surprise',\n 'anger',\n 'happy',\n 'anger',\n 'surprise',\n 'fear',\n 'neutral',\n 'happy',\n 'contempt',\n 'happy',\n 'happy',\n 'fear',\n 'happy',\n 'anger',\n 'anger',\n 'neutral',\n 'surprise',\n 'happy',\n 'sad',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'disgust',\n 'happy',\n 'neutral',\n 'fear',\n 'surprise',\n 'surprise',\n 'neutral',\n 'anger',\n 'contempt',\n 'happy',\n 'neutral',\n 'happy',\n 'sad',\n 'happy',\n 'surprise',\n 'happy',\n 'happy',\n 'surprise',\n 'fear',\n 'contempt',\n 'contempt',\n 'neutral',\n 'sad',\n 'fear',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'sad',\n 'anger',\n 'happy',\n 'neutral',\n 'sad',\n 'anger',\n 'happy',\n 'sad',\n 'surprise',\n 'neutral',\n 'happy',\n 'contempt',\n 'neutral',\n 'fear',\n 'neutral',\n 'neutral',\n 'happy',\n 'contempt',\n 'fear',\n 'happy',\n 'happy',\n 'surprise',\n 'surprise',\n 'happy',\n 'anger',\n 'neutral',\n 'contempt',\n 'contempt',\n 'neutral',\n 'sad',\n 'contempt',\n 'disgust',\n 'sad',\n 'happy',\n 'happy',\n 'disgust',\n 'happy',\n 'neutral',\n 'fear',\n 'neutral',\n 'anger',\n 'surprise',\n 'neutral',\n 'contempt',\n 'sad',\n 'surprise',\n 'neutral',\n 'neutral',\n 'fear',\n 'sad',\n 'anger',\n 'neutral',\n 'happy',\n 'anger',\n 'neutral',\n 'contempt',\n 'contempt',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'fear',\n 'fear',\n 'happy',\n 'happy',\n 'contempt',\n 'happy',\n 'contempt',\n 'happy',\n 'sad',\n 'fear',\n 'sad',\n 'surprise',\n 'disgust',\n 'disgust',\n 'neutral',\n 'happy',\n 'contempt',\n 'fear',\n 'sad',\n 'happy',\n 'surprise',\n 'anger',\n 'contempt',\n 'fear',\n 'fear',\n 'disgust',\n 'fear',\n 'anger',\n 'neutral',\n 'neutral',\n 'anger',\n 'happy',\n 'neutral',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'fear',\n 'happy',\n 'sad',\n 'neutral',\n 'contempt',\n 'disgust',\n 'neutral',\n 'anger',\n 'surprise',\n 'sad',\n 'neutral',\n 'anger',\n 'happy',\n 'neutral',\n 'contempt',\n 'fear',\n 'neutral',\n 'happy',\n 'disgust',\n 'surprise',\n 'anger',\n 'neutral',\n 'disgust',\n 'contempt',\n 'sad',\n 'neutral',\n 'surprise',\n 'fear',\n 'disgust',\n 'surprise',\n 'anger',\n 'happy',\n 'contempt',\n 'disgust',\n 'surprise',\n 'happy',\n 'surprise',\n 'surprise',\n 'contempt',\n 'disgust',\n 'happy',\n 'anger',\n 'contempt',\n 'happy',\n 'happy',\n 'surprise',\n 'surprise',\n 'sad',\n 'happy',\n 'sad',\n 'sad',\n 'happy',\n 'surprise',\n 'fear',\n 'fear',\n 'surprise',\n 'anger',\n 'anger',\n 'happy',\n 'sad',\n 'neutral',\n 'sad',\n 'sad',\n 'neutral',\n 'happy',\n 'happy',\n 'disgust',\n 'fear',\n 'disgust',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'neutral',\n 'contempt',\n 'contempt',\n 'surprise',\n 'fear',\n 'anger',\n 'contempt',\n 'surprise',\n 'contempt',\n 'fear',\n 'fear',\n 'anger',\n 'surprise',\n 'disgust',\n 'surprise',\n 'neutral',\n 'neutral',\n 'sad',\n 'disgust',\n 'anger',\n 'surprise',\n 'contempt',\n 'fear',\n 'happy',\n 'disgust',\n 'fear',\n 'sad',\n 'disgust',\n 'sad',\n 'neutral',\n 'happy',\n 'contempt',\n 'fear',\n 'sad',\n 'anger',\n 'anger',\n 'sad',\n 'sad',\n 'neutral',\n 'sad',\n 'surprise',\n 'fear',\n 'surprise',\n 'neutral',\n 'anger',\n 'anger',\n 'neutral',\n 'neutral',\n 'surprise',\n 'happy',\n 'sad',\n 'happy',\n 'surprise',\n 'surprise',\n 'disgust',\n 'neutral',\n 'happy',\n 'neutral',\n 'disgust',\n 'happy',\n 'anger',\n 'contempt',\n 'contempt',\n 'surprise',\n 'neutral',\n 'surprise',\n 'happy',\n 'happy',\n 'contempt',\n 'sad',\n 'surprise',\n 'neutral',\n 'fear',\n 'disgust',\n 'fear',\n 'anger',\n 'happy',\n 'happy',\n 'anger',\n 'surprise',\n 'surprise',\n 'happy',\n 'anger',\n 'sad',\n 'neutral',\n 'fear',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'sad',\n 'fear',\n 'neutral',\n 'contempt',\n 'contempt',\n 'sad',\n 'happy',\n 'neutral',\n 'sad',\n 'surprise',\n 'neutral',\n 'neutral',\n 'happy',\n 'fear',\n 'fear',\n 'happy',\n 'happy',\n 'happy',\n 'happy',\n 'neutral',\n 'happy',\n 'sad',\n 'fear',\n 'happy',\n 'contempt',\n 'surprise',\n 'neutral',\n 'neutral',\n 'happy',\n 'sad',\n 'neutral',\n 'neutral',\n 'surprise',\n 'anger',\n 'contempt',\n 'sad',\n 'disgust',\n 'neutral',\n 'happy',\n 'surprise',\n 'surprise',\n 'disgust',\n 'fear',\n 'surprise',\n 'sad',\n 'fear',\n 'surprise',\n 'neutral',\n 'contempt',\n 'anger',\n 'happy',\n 'contempt',\n 'disgust',\n 'anger',\n 'contempt',\n 'contempt',\n 'neutral',\n 'disgust',\n 'fear',\n 'surprise',\n 'surprise',\n 'fear',\n 'anger',\n 'happy',\n 'fear',\n 'sad',\n 'neutral',\n 'surprise',\n 'disgust',\n 'fear',\n 'happy',\n 'happy',\n 'disgust',\n 'fear',\n 'fear',\n 'happy',\n 'neutral',\n 'neutral',\n 'neutral',\n 'disgust',\n 'surprise',\n 'fear',\n 'neutral',\n 'sad',\n 'surprise',\n 'surprise',\n 'fear',\n 'disgust',\n 'sad',\n 'sad',\n 'fear',\n 'neutral',\n 'contempt',\n 'anger',\n 'fear',\n 'happy',\n 'neutral',\n 'happy',\n 'contempt',\n 'anger',\n 'fear',\n 'sad',\n 'sad',\n 'disgust',\n 'disgust',\n 'contempt',\n 'fear',\n 'happy',\n 'surprise',\n 'anger',\n 'sad',\n 'happy',\n 'sad',\n 'happy',\n 'happy',\n 'neutral',\n 'surprise',\n 'contempt',\n 'happy',\n 'neutral',\n 'anger',\n 'neutral',\n 'sad',\n 'fear',\n 'anger',\n 'happy',\n 'fear',\n 'disgust',\n 'surprise',\n 'neutral',\n 'neutral',\n 'anger',\n 'sad',\n 'surprise',\n 'sad',\n 'contempt',\n 'happy',\n 'disgust',\n 'anger',\n 'happy',\n 'surprise',\n 'fear',\n 'surprise',\n 'neutral',\n 'fear',\n 'happy',\n 'disgust',\n 'surprise',\n 'anger',\n 'neutral',\n 'happy',\n 'disgust',\n 'contempt',\n 'happy',\n 'neutral',\n 'fear',\n 'disgust',\n 'happy',\n 'happy',\n 'happy',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'disgust',\n 'neutral',\n 'anger',\n 'fear',\n 'sad',\n 'happy',\n 'fear',\n 'anger',\n 'surprise',\n 'anger',\n 'fear',\n 'sad',\n 'happy',\n 'anger',\n 'contempt',\n 'contempt',\n 'happy',\n 'surprise',\n 'fear',\n 'anger',\n 'happy',\n 'anger',\n 'anger',\n 'disgust',\n 'surprise',\n 'neutral',\n 'neutral',\n 'surprise',\n 'contempt',\n 'sad',\n 'sad',\n 'surprise',\n 'sad',\n 'sad',\n 'sad',\n 'anger',\n 'sad',\n 'fear',\n 'neutral',\n 'sad',\n 'disgust',\n 'happy',\n 'neutral',\n 'neutral',\n 'disgust',\n 'neutral',\n 'neutral',\n 'neutral',\n 'neutral',\n 'sad',\n 'contempt',\n 'fear',\n 'anger',\n 'neutral',\n 'surprise',\n 'happy',\n 'surprise',\n 'neutral',\n 'contempt',\n 'surprise',\n 'surprise',\n 'happy',\n 'happy',\n 'happy',\n 'surprise',\n 'neutral',\n 'happy',\n 'surprise',\n 'neutral',\n 'neutral',\n 'anger',\n 'contempt',\n 'happy',\n 'fear',\n 'contempt',\n 'happy',\n 'sad',\n 'fear',\n 'fear',\n 'happy',\n 'disgust',\n 'surprise',\n 'neutral',\n 'surprise',\n 'anger',\n 'sad',\n ...]"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd[\"predict\"].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:45:14.424953343Z",
     "start_time": "2023-09-09T02:45:14.416036099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1_score(test['col1404'], pd[\"predict\"].tolist(), average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
