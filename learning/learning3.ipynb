{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:30:50.860771113Z",
     "start_time": "2023-09-09T01:30:50.857301837Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas_profiling as pp\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data2/landmarks.csv')\n",
    "df.columns = [f'col{i}' for i in range(1405)]\n",
    "df.astype({'col1404':'string'})\n",
    "\n",
    "Y = df.iloc[:]['col1404']\n",
    "X = df.drop(columns=['col1404'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:31:44.249883006Z",
     "start_time": "2023-09-09T01:31:37.534904571Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['surprise', 'anger', 'contempt', 'sad', 'happy', 'disgust',\n       'neutral', 'fear'], dtype=object)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:33:45.613464803Z",
     "start_time": "2023-09-09T01:33:45.599133534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  -----------------------------\nH2O_cluster_uptime:         4 hours 29 mins\nH2O_cluster_timezone:       Europe/Moscow\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.42.0.3\nH2O_cluster_version_age:    17 days\nH2O_cluster_name:           H2O_from_python_vorkov_s0lk7n\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    7.731 Gb\nH2O_cluster_total_cores:    12\nH2O_cluster_allowed_cores:  8\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://localhost:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.8.10 final\n--------------------------  -----------------------------",
      "text/html": "\n<style>\n\n#h2o-table-18.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-18 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-18 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-18 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-18 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-18 .h2o-table th,\n#h2o-table-18 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-18 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-18\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>4 hours 29 mins</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Moscow</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.42.0.3</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>17 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_vorkov_s0lk7n</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>7.731 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>12</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.8.10 final</td></tr></tbody>\n  </table>\n</div>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(\n",
    "    nthreads=8,     # number of threads when launching a new H2O server\n",
    "    max_mem_size=8  # in gigabytes\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:33:52.253384477Z",
     "start_time": "2023-09-09T01:33:52.191290884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "col1404\nanger       3159\ncontempt    2857\ndisgust        1\nhappy       5038\nneutral     5117\nsurprise    4019\nName: col1404, dtype: int64"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.groupby(\"col1404\")[\"col1404\"].count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:28:16.450016916Z",
     "start_time": "2023-09-09T01:28:16.438195738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "04:36:41.602: Project: AutoML_2_20230909_43641\n",
      "04:36:41.602: 5-fold cross-validation will be used.\n",
      "04:36:41.603: Setting stopping tolerance adaptively based on the training frame: 0.006386420048890296\n",
      "04:36:41.603: Build control seed: 1\n",
      "04:36:41.604: training frame: Frame key: AutoML_2_20230909_43641_training_Key_Frame__upload_ae3d0a5414d9ea46ac6abb67ac324507.hex    cols: 1405    rows: 24518  chunks: 157    size: 290473276  checksum: 9014670398134974866\n",
      "04:36:41.604: validation frame: NULL\n",
      "04:36:41.604: leaderboard frame: NULL\n",
      "04:36:41.604: blending frame: NULL\n",
      "04:36:41.604: response column: col1404\n",
      "04:36:41.604: fold column: null\n",
      "04:36:41.604: weights column: null\n",
      "04:36:41.608: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
      "04:36:41.610: AutoML job created: 2023.09.09 04:36:41.598\n",
      "04:36:41.610: AutoML build started: 2023.09.09 04:36:41.610\n",
      "04:36:41.618: AutoML: starting XGBoost_1_AutoML_2_20230909_43641 model training\n",
      "███████"
     ]
    }
   ],
   "source": [
    "train = xtrain\n",
    "train[\"col1404\"] = ytrain\n",
    "\n",
    "test = xtest\n",
    "test[\"col1404\"] = ytest\n",
    "\n",
    "train_h2o_frame = h2o.H2OFrame(train)\n",
    "test_h2o_frame = h2o.H2OFrame(test)\n",
    "\n",
    "x = train_h2o_frame.columns\n",
    "y = \"col1404\"\n",
    "x.remove(y)\n",
    "\n",
    "aml = H2OAutoML(max_models=8, seed=1, max_runtime_secs=60*60, verbosity='info')\n",
    "aml.train(x=x, y=y, training_frame=train_h2o_frame)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-09T01:36:00.963441069Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'AUTO'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "model_id                             mean_per_class_error    logloss      rmse       mse\n---------------------------------  ----------------------  ---------  --------  --------\nGLM_1_AutoML_1_20230909_00442                    0.358946   0.588139  0.428383  0.183512\nXGBoost_1_AutoML_1_20230909_00442                0.384425   0.629443  0.435483  0.189645\n[2 rows x 5 columns]\n",
      "text/html": "<table class='dataframe'>\n<thead>\n<tr><th>model_id                         </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n</thead>\n<tbody>\n<tr><td>GLM_1_AutoML_1_20230909_00442    </td><td style=\"text-align: right;\">              0.358946</td><td style=\"text-align: right;\"> 0.588139</td><td style=\"text-align: right;\">0.428383</td><td style=\"text-align: right;\">0.183512</td></tr>\n<tr><td>XGBoost_1_AutoML_1_20230909_00442</td><td style=\"text-align: right;\">              0.384425</td><td style=\"text-align: right;\"> 0.629443</td><td style=\"text-align: right;\">0.435483</td><td style=\"text-align: right;\">0.189645</td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[2 rows x 5 columns]</pre>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T22:27:45.900360690Z",
     "start_time": "2023-09-08T22:27:45.857681608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test_h2o_frame = test_h2o_frame.drop('col1404')\n",
    "pred = aml.predict(test_h2o_frame)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T22:29:58.810267257Z",
     "start_time": "2023-09-08T22:29:58.487689609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "predict       anger    contempt      disgust        happy      neutral    surprise\n---------  --------  ----------  -----------  -----------  -----------  ----------\nanger      0.785474  0.00315324  7.16687e-07  0.000155655  2.75566e-06  0.211214\nanger      0.513401  0.224812    1.63442e-05  7.30381e-05  0.00407176   0.257626\nanger      0.915206  0.0457143   4.95148e-06  1.73313e-05  0.0040324    0.0350254\nanger      0.858818  0.00353934  1.40306e-06  3.76374e-05  1.14827e-05  0.137592\ncontempt   0.260427  0.48689     2.40392e-05  0.00255855   0.0118256    0.238274\nanger      0.732838  0.091804    1.497e-05    7.53426e-05  0.0174777    0.15779\nanger      0.828043  0.0637554   3.51999e-07  3.13452e-07  0.000490878  0.10771\nanger      0.889751  0.106978    2.23184e-06  5.22006e-05  4.08157e-05  0.00317531\nanger      0.56497   0.178844    7.34457e-06  0.000578934  0.038937     0.216663\nanger      0.326414  0.152872    5.89797e-05  0.00278635   0.19269      0.325179\n[4327 rows x 7 columns]\n",
      "text/html": "<table class='dataframe'>\n<thead>\n<tr><th>predict  </th><th style=\"text-align: right;\">   anger</th><th style=\"text-align: right;\">  contempt</th><th style=\"text-align: right;\">    disgust</th><th style=\"text-align: right;\">      happy</th><th style=\"text-align: right;\">    neutral</th><th style=\"text-align: right;\">  surprise</th></tr>\n</thead>\n<tbody>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.785474</td><td style=\"text-align: right;\">0.00315324</td><td style=\"text-align: right;\">7.16687e-07</td><td style=\"text-align: right;\">0.000155655</td><td style=\"text-align: right;\">2.75566e-06</td><td style=\"text-align: right;\">0.211214  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.513401</td><td style=\"text-align: right;\">0.224812  </td><td style=\"text-align: right;\">1.63442e-05</td><td style=\"text-align: right;\">7.30381e-05</td><td style=\"text-align: right;\">0.00407176 </td><td style=\"text-align: right;\">0.257626  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.915206</td><td style=\"text-align: right;\">0.0457143 </td><td style=\"text-align: right;\">4.95148e-06</td><td style=\"text-align: right;\">1.73313e-05</td><td style=\"text-align: right;\">0.0040324  </td><td style=\"text-align: right;\">0.0350254 </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.858818</td><td style=\"text-align: right;\">0.00353934</td><td style=\"text-align: right;\">1.40306e-06</td><td style=\"text-align: right;\">3.76374e-05</td><td style=\"text-align: right;\">1.14827e-05</td><td style=\"text-align: right;\">0.137592  </td></tr>\n<tr><td>contempt </td><td style=\"text-align: right;\">0.260427</td><td style=\"text-align: right;\">0.48689   </td><td style=\"text-align: right;\">2.40392e-05</td><td style=\"text-align: right;\">0.00255855 </td><td style=\"text-align: right;\">0.0118256  </td><td style=\"text-align: right;\">0.238274  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.732838</td><td style=\"text-align: right;\">0.091804  </td><td style=\"text-align: right;\">1.497e-05  </td><td style=\"text-align: right;\">7.53426e-05</td><td style=\"text-align: right;\">0.0174777  </td><td style=\"text-align: right;\">0.15779   </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.828043</td><td style=\"text-align: right;\">0.0637554 </td><td style=\"text-align: right;\">3.51999e-07</td><td style=\"text-align: right;\">3.13452e-07</td><td style=\"text-align: right;\">0.000490878</td><td style=\"text-align: right;\">0.10771   </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.889751</td><td style=\"text-align: right;\">0.106978  </td><td style=\"text-align: right;\">2.23184e-06</td><td style=\"text-align: right;\">5.22006e-05</td><td style=\"text-align: right;\">4.08157e-05</td><td style=\"text-align: right;\">0.00317531</td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.56497 </td><td style=\"text-align: right;\">0.178844  </td><td style=\"text-align: right;\">7.34457e-06</td><td style=\"text-align: right;\">0.000578934</td><td style=\"text-align: right;\">0.038937   </td><td style=\"text-align: right;\">0.216663  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.326414</td><td style=\"text-align: right;\">0.152872  </td><td style=\"text-align: right;\">5.89797e-05</td><td style=\"text-align: right;\">0.00278635 </td><td style=\"text-align: right;\">0.19269    </td><td style=\"text-align: right;\">0.325179  </td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[4327 rows x 7 columns]</pre>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T22:30:23.279191708Z",
     "start_time": "2023-09-08T22:30:23.253532970Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "best_model = aml.leader\n",
    "# aml.score(test_h2o_frame, test_h2o_frame.MEDV)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T23:09:12.980013251Z",
     "start_time": "2023-09-08T23:09:12.930294802Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/vorkov/Workspace/Emotion-Decetion-Service/learning/GLM_1_AutoML_1_20230909_00442'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(model=best_model, path=\"./\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T23:10:54.141881800Z",
     "start_time": "2023-09-08T23:10:54.129884200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n\n\nGLM Model: summary\n    family       link         regularization               lambda_search                                                                   number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n--  -----------  -----------  ---------------------------  ------------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  ---------------------------------------------------------------------------------------\n    multinomial  multinomial  Ridge ( lambda = 0.007732 )  nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062  8430                          8424                           205                     AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex\n\nModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2146     420         0          18       46         529         0.320671   1,013 / 3,159\n429      1948        0          47       84         349         0.318166   909 / 2,857\n1        0           0          0        0          0           1          1 / 1\n12       23          0          4407     553        43          0.125248   631 / 5,038\n46       38          0          316      4614       103         0.0982998  503 / 5,117\n383      360         0          104      325        2847        0.291615   1,172 / 4,019\n3017     2789        0          4892     5622       3871        0.20945    4,229 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.79055\n2    0.942301\n3    0.984349\n4    0.997524\n5    0.999851\n6    1\n\nModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2125     436         0          17       46         535         0.327319   1,034 / 3,159\n407      1972        0          46       84         348         0.309765   885 / 2,857\n1        0           0          0        0          0           1          1 / 1\n11       22          0          4405     554        46          0.125645   633 / 5,038\n46       38          0          316      4610       107         0.0990815  507 / 5,117\n389      361         0          100      323        2846        0.291864   1,173 / 4,019\n2979     2829        0          4884     5617       3882        0.209648   4,233 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.790352\n2    0.942152\n3    0.984102\n4    0.997573\n5    0.999852\n6    1\n\nCross-Validation Metrics Summary: \n                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.7906    0.00603916  0.791533      0.795691      0.789004      0.795691      0.78108\nauc                      nan       0           nan           nan           nan           nan           nan\nerr                      0.2094    0.00603916  0.208467      0.204309      0.210996      0.204309      0.21892\nerr_count                845.6     24.3783     842           825           852           825           884\nlogloss                  0.588093  0.0150114   0.601342      0.566701      0.589262      0.58057       0.602593\nmax_per_class_error      0.463815  0.299812    1             0.325949      0.34019       0.330696      0.322242\nmean_per_class_accuracy  0.774628  0.0748648   0.640994      0.812372      0.807228      0.812219      0.800326\nmean_per_class_error     0.225372  0.0748648   0.359006      0.187628      0.192772      0.187781      0.199674\nmse                      0.183476  0.00422378  0.186501      0.17799       0.185417      0.179982      0.187492\nnull_deviance            inf       nan         inf           12781.9       12780.7       12780.7       12780.2\npr_auc                   nan       0           nan           nan           nan           nan           nan\nr2                       0.939117  0.00141633  0.938089      0.94096       0.938478      0.940282      0.937774\nresidual_deviance        4749.72   121.538     4857.82       4576.68       4758.88       4688.68       4866.54\nrmse                     0.428319  0.00494095  0.431858      0.421888      0.430601      0.424242      0.433004\n\nScoring History: \n     timestamp            duration    iteration    lambda    predictors    deviance_train      deviance_xval       deviance_se            alpha    iterations    training_rmse       training_logloss    training_r2         training_classification_error    training_auc    training_pr_auc\n---  -------------------  ----------  -----------  --------  ------------  ------------------  ------------------  ---------------------  -------  ------------  ------------------  ------------------  ------------------  -------------------------------  --------------  -----------------\n     2023-09-09 00:44:00  0.000 sec   5            .22E2     8430          2.248140716119977   5.149931681186062   2.834724413204253      0.0\n     2023-09-09 00:44:00  0.677 sec   8            .16E2     8430          2.1535965161010697  5.0728719149317865  2.8539895652773546     0.0\n     2023-09-09 00:44:01  1.367 sec   12           .12E2     8430          2.062910412015913   2.12673455827772    0.0030129313526652754  0.0\n     2023-09-09 00:44:02  2.145 sec   16           .84E1     8430          1.9758453973316426  2.0371638351436987  0.003449756456666322   0.0\n     2023-09-09 00:44:03  3.117 sec   21           .61E1     8430          1.8925664407633036  1.9516812892231576  0.003938013706845999   0.0\n     2023-09-09 00:44:04  4.269 sec   26           .44E1     8430          1.8151123413826604  1.8703869552280885  0.004312489632431074   0.0\n     2023-09-09 00:44:05  5.408 sec   32           .32E1     8430          1.742629542726998   1.7921155853469783  0.004915638897145258   0.0\n     2023-09-09 00:44:06  6.448 sec   38           .24E1     8430          1.6742460670408088  1.722363487570209   0.005382304566046644   0.0\n     2023-09-09 00:44:07  7.583 sec   44           .17E1     8430          1.605945624848216   1.653229909846932   0.005549571198674038   0.0\n     2023-09-09 00:44:08  8.727 sec   50           .12E1     8430          1.546692054948466   1.5902172649935753  0.006997583138672032   0.0\n---  ---                  ---         ---          ---       ---           ---                 ---                 ---                    ---      ---           ---                 ---                 ---                 ---                              ---             ---\n     2023-09-09 00:44:32  32.010 sec  171          .38E-1    8430          1.2047304117119122  1.219371956915976   0.01171535704375587    0.0\n     2023-09-09 00:44:32  32.307 sec  172          .28E-1    8430          1.2045839758418027  1.2145364839233266  0.010951542185820255   0.0\n     2023-09-09 00:44:38  38.306 sec  201          .2E-1     8430          1.170156009321884   1.2028762552323793  0.007375434935290969   0.0\n     2023-09-09 00:44:38  38.682 sec  203          .15E-1    8430          1.1698353588678703  1.1946579373603106  0.007271888535685163   0.0\n     2023-09-09 00:44:39  38.964 sec  204          .11E-1    8430          1.1697612737323517  1.1861467449604013  0.01424862623234221    0.0\n     2023-09-09 00:44:39  39.151 sec  205          .77E-2    8430          1.1696957862297173  1.1762900748535214  0.01344541482508615    0.0\n     2023-09-09 00:44:39  39.433 sec  206          .56E-2    8430          1.1696321484590473  1.1763251144765063  0.013439865599289018   0.0\n     2023-09-09 00:44:39  39.627 sec  207          .41E-2    8430          1.1695627962171948  1.528804480722551   0.35997155430461053    0.0\n     2023-09-09 00:44:39  39.917 sec  208          .3E-2     8430          1.169494213685578   1.7391552026800745  0.24224461444307635    0.0\n     2023-09-09 00:44:40  40.108 sec  209          .22E-2    8430          1.1694212595229305  0.0                 0.0                    0.0      209           0.4280754520274582  0.5848479289901717  0.9391926917188472  0.2094497548412659               nan             nan\n[30 rows x 17 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance     percentage\n----------  ---------------------  --------------------  ----------------------\ncol874      0.2500748336315155     1.0                   0.002491267590981969\ncol919      0.24001291394233704    0.9597643651579724    0.0023910298578974404\ncol166      0.2380715012550354     0.9520010382405493    0.0023716893331498664\ncol862      0.2356162667274475     0.9421830389963484    0.002347230069824503\ncol44       0.23441898822784424    0.9373953581161225    0.002335302675611632\ncol196      0.23107394576072693    0.9240191921959395    0.002301979066963083\ncol877      0.23084664344787598    0.9231102550208142    0.002299714661236455\ncol322      0.22571641206741333    0.9025954702823307    0.0022486068428814988\ncol925      0.21996857225894928    0.8796109910966583    0.0021913463547906338\ncol184      0.21731959283351898    0.8690182441698181    0.002164956987672323\n---         ---                    ---                   ---\ncol0        0.011895542033016682   0.047567929408461496  0.0001185044409054182\ncol392      0.011644117534160614   0.0465625323630853    0.00011599972783020348\ncol36       0.01144136767834425    0.04575177562730311   0.00011397991585017895\ncol98       0.010843622498214245   0.04336151039569335   0.00010802512554481857\ncol740      0.010798311792314053   0.04318032180809258   0.00010757373628867297\ncol788      0.0101018650457263     0.04039536845443379   0.00010063567225630627\ncol92       0.010025384835898876   0.04008953916039088   9.98737696476843e-05\ncol39       0.00972403772175312    0.03888451141021835   9.687172306744555e-05\ncol743      0.00782020017504692    0.03127144007849251   7.790552519088302e-05\ncol1298     0.007329002022743225   0.029307235423547205  7.301216579196186e-05\n[1404 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-10.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-10 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-10 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-10 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-10 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-10 .h2o-table th,\n#h2o-table-10 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-10 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-10\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>GLM Model: summary</caption>\n    <thead><tr><th></th>\n<th>family</th>\n<th>link</th>\n<th>regularization</th>\n<th>lambda_search</th>\n<th>number_of_predictors_total</th>\n<th>number_of_active_predictors</th>\n<th>number_of_iterations</th>\n<th>training_frame</th></tr></thead>\n    <tbody><tr><td></td>\n<td>multinomial</td>\n<td>multinomial</td>\n<td>Ridge ( lambda = 0.007732 )</td>\n<td>nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062</td>\n<td>8430</td>\n<td>8424</td>\n<td>205</td>\n<td>AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-11.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-11 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-11 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-11 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-11 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-11 .h2o-table th,\n#h2o-table-11 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-11 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-11\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2146.0</td>\n<td>420.0</td>\n<td>0.0</td>\n<td>18.0</td>\n<td>46.0</td>\n<td>529.0</td>\n<td>0.3206711</td>\n<td>1,013 / 3,159</td></tr>\n<tr><td>429.0</td>\n<td>1948.0</td>\n<td>0.0</td>\n<td>47.0</td>\n<td>84.0</td>\n<td>349.0</td>\n<td>0.3181659</td>\n<td>909 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>12.0</td>\n<td>23.0</td>\n<td>0.0</td>\n<td>4407.0</td>\n<td>553.0</td>\n<td>43.0</td>\n<td>0.1252481</td>\n<td>631 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4614.0</td>\n<td>103.0</td>\n<td>0.0982998</td>\n<td>503 / 5,117</td></tr>\n<tr><td>383.0</td>\n<td>360.0</td>\n<td>0.0</td>\n<td>104.0</td>\n<td>325.0</td>\n<td>2847.0</td>\n<td>0.2916148</td>\n<td>1,172 / 4,019</td></tr>\n<tr><td>3017.0</td>\n<td>2789.0</td>\n<td>0.0</td>\n<td>4892.0</td>\n<td>5622.0</td>\n<td>3871.0</td>\n<td>0.2094498</td>\n<td>4,229 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-12.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-12 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-12 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-12 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-12 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-12 .h2o-table th,\n#h2o-table-12 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-12 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-12\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7905502</td></tr>\n<tr><td>2</td>\n<td>0.9423010</td></tr>\n<tr><td>3</td>\n<td>0.9843495</td></tr>\n<tr><td>4</td>\n<td>0.9975237</td></tr>\n<tr><td>5</td>\n<td>0.9998514</td></tr>\n<tr><td>6</td>\n<td>1.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-13.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-13 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-13 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-13 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-13 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-13 .h2o-table th,\n#h2o-table-13 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-13 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-13\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2125.0</td>\n<td>436.0</td>\n<td>0.0</td>\n<td>17.0</td>\n<td>46.0</td>\n<td>535.0</td>\n<td>0.3273188</td>\n<td>1,034 / 3,159</td></tr>\n<tr><td>407.0</td>\n<td>1972.0</td>\n<td>0.0</td>\n<td>46.0</td>\n<td>84.0</td>\n<td>348.0</td>\n<td>0.3097655</td>\n<td>885 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>11.0</td>\n<td>22.0</td>\n<td>0.0</td>\n<td>4405.0</td>\n<td>554.0</td>\n<td>46.0</td>\n<td>0.1256451</td>\n<td>633 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4610.0</td>\n<td>107.0</td>\n<td>0.0990815</td>\n<td>507 / 5,117</td></tr>\n<tr><td>389.0</td>\n<td>361.0</td>\n<td>0.0</td>\n<td>100.0</td>\n<td>323.0</td>\n<td>2846.0</td>\n<td>0.2918636</td>\n<td>1,173 / 4,019</td></tr>\n<tr><td>2979.0</td>\n<td>2829.0</td>\n<td>0.0</td>\n<td>4884.0</td>\n<td>5617.0</td>\n<td>3882.0</td>\n<td>0.2096479</td>\n<td>4,233 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-14.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-14 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-14 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-14 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-14 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-14 .h2o-table th,\n#h2o-table-14 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-14 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-14\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7903522</td></tr>\n<tr><td>2</td>\n<td>0.9421525</td></tr>\n<tr><td>3</td>\n<td>0.9841019</td></tr>\n<tr><td>4</td>\n<td>0.9975733</td></tr>\n<tr><td>5</td>\n<td>0.9998515</td></tr>\n<tr><td>6</td>\n<td>1.0000001</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-15.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-15 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-15 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-15 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-15 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-15 .h2o-table th,\n#h2o-table-15 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-15 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-15\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.7905997</td>\n<td>0.0060392</td>\n<td>0.7915326</td>\n<td>0.7956910</td>\n<td>0.7890044</td>\n<td>0.7956910</td>\n<td>0.7810798</td></tr>\n<tr><td>auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>err</td>\n<td>0.2094003</td>\n<td>0.0060392</td>\n<td>0.2084674</td>\n<td>0.2043091</td>\n<td>0.2109955</td>\n<td>0.2043091</td>\n<td>0.2189203</td></tr>\n<tr><td>err_count</td>\n<td>845.6</td>\n<td>24.37827</td>\n<td>842.0</td>\n<td>825.0</td>\n<td>852.0</td>\n<td>825.0</td>\n<td>884.0</td></tr>\n<tr><td>logloss</td>\n<td>0.5880934</td>\n<td>0.0150114</td>\n<td>0.6013420</td>\n<td>0.5667007</td>\n<td>0.5892617</td>\n<td>0.5805697</td>\n<td>0.6025928</td></tr>\n<tr><td>max_per_class_error</td>\n<td>0.4638154</td>\n<td>0.2998116</td>\n<td>1.0</td>\n<td>0.3259494</td>\n<td>0.3401899</td>\n<td>0.3306962</td>\n<td>0.3222417</td></tr>\n<tr><td>mean_per_class_accuracy</td>\n<td>0.7746276</td>\n<td>0.0748648</td>\n<td>0.6409936</td>\n<td>0.812372</td>\n<td>0.8072276</td>\n<td>0.8122187</td>\n<td>0.8003262</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.2253724</td>\n<td>0.0748648</td>\n<td>0.3590064</td>\n<td>0.1876280</td>\n<td>0.1927724</td>\n<td>0.1877813</td>\n<td>0.1996739</td></tr>\n<tr><td>mse</td>\n<td>0.1834765</td>\n<td>0.0042238</td>\n<td>0.1865014</td>\n<td>0.1779897</td>\n<td>0.1854174</td>\n<td>0.1799816</td>\n<td>0.1874921</td></tr>\n<tr><td>null_deviance</td>\n<td>inf</td>\n<td>nan</td>\n<td>inf</td>\n<td>12781.859</td>\n<td>12780.725</td>\n<td>12780.725</td>\n<td>12780.242</td></tr>\n<tr><td>pr_auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>r2</td>\n<td>0.9391168</td>\n<td>0.0014163</td>\n<td>0.9380893</td>\n<td>0.9409605</td>\n<td>0.9384785</td>\n<td>0.9402820</td>\n<td>0.9377737</td></tr>\n<tr><td>residual_deviance</td>\n<td>4749.718</td>\n<td>121.53792</td>\n<td>4857.817</td>\n<td>4576.675</td>\n<td>4758.8774</td>\n<td>4688.681</td>\n<td>4866.5396</td></tr>\n<tr><td>rmse</td>\n<td>0.4283187</td>\n<td>0.0049410</td>\n<td>0.4318581</td>\n<td>0.4218883</td>\n<td>0.4306012</td>\n<td>0.4242424</td>\n<td>0.4330036</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-16.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-16 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-16 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-16 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-16 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-16 .h2o-table th,\n#h2o-table-16 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-16 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-16\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>iteration</th>\n<th>lambda</th>\n<th>predictors</th>\n<th>deviance_train</th>\n<th>deviance_xval</th>\n<th>deviance_se</th>\n<th>alpha</th>\n<th>iterations</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_r2</th>\n<th>training_classification_error</th>\n<th>training_auc</th>\n<th>training_pr_auc</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.000 sec</td>\n<td>5</td>\n<td>.22E2</td>\n<td>8430</td>\n<td>2.2481407</td>\n<td>5.1499317</td>\n<td>2.8347244</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.677 sec</td>\n<td>8</td>\n<td>.16E2</td>\n<td>8430</td>\n<td>2.1535965</td>\n<td>5.0728719</td>\n<td>2.8539896</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:01</td>\n<td> 1.367 sec</td>\n<td>12</td>\n<td>.12E2</td>\n<td>8430</td>\n<td>2.0629104</td>\n<td>2.1267346</td>\n<td>0.0030129</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:02</td>\n<td> 2.145 sec</td>\n<td>16</td>\n<td>.84E1</td>\n<td>8430</td>\n<td>1.9758454</td>\n<td>2.0371638</td>\n<td>0.0034498</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:03</td>\n<td> 3.117 sec</td>\n<td>21</td>\n<td>.61E1</td>\n<td>8430</td>\n<td>1.8925664</td>\n<td>1.9516813</td>\n<td>0.0039380</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:04</td>\n<td> 4.269 sec</td>\n<td>26</td>\n<td>.44E1</td>\n<td>8430</td>\n<td>1.8151123</td>\n<td>1.8703870</td>\n<td>0.0043125</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:05</td>\n<td> 5.408 sec</td>\n<td>32</td>\n<td>.32E1</td>\n<td>8430</td>\n<td>1.7426295</td>\n<td>1.7921156</td>\n<td>0.0049156</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:06</td>\n<td> 6.448 sec</td>\n<td>38</td>\n<td>.24E1</td>\n<td>8430</td>\n<td>1.6742461</td>\n<td>1.7223635</td>\n<td>0.0053823</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:07</td>\n<td> 7.583 sec</td>\n<td>44</td>\n<td>.17E1</td>\n<td>8430</td>\n<td>1.6059456</td>\n<td>1.6532299</td>\n<td>0.0055496</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:08</td>\n<td> 8.727 sec</td>\n<td>50</td>\n<td>.12E1</td>\n<td>8430</td>\n<td>1.5466921</td>\n<td>1.5902173</td>\n<td>0.0069976</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.010 sec</td>\n<td>171</td>\n<td>.38E-1</td>\n<td>8430</td>\n<td>1.2047304</td>\n<td>1.2193720</td>\n<td>0.0117154</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.307 sec</td>\n<td>172</td>\n<td>.28E-1</td>\n<td>8430</td>\n<td>1.2045840</td>\n<td>1.2145365</td>\n<td>0.0109515</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.306 sec</td>\n<td>201</td>\n<td>.2E-1</td>\n<td>8430</td>\n<td>1.1701560</td>\n<td>1.2028763</td>\n<td>0.0073754</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.682 sec</td>\n<td>203</td>\n<td>.15E-1</td>\n<td>8430</td>\n<td>1.1698354</td>\n<td>1.1946579</td>\n<td>0.0072719</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>38.964 sec</td>\n<td>204</td>\n<td>.11E-1</td>\n<td>8430</td>\n<td>1.1697613</td>\n<td>1.1861467</td>\n<td>0.0142486</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.151 sec</td>\n<td>205</td>\n<td>.77E-2</td>\n<td>8430</td>\n<td>1.1696958</td>\n<td>1.1762901</td>\n<td>0.0134454</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.433 sec</td>\n<td>206</td>\n<td>.56E-2</td>\n<td>8430</td>\n<td>1.1696321</td>\n<td>1.1763251</td>\n<td>0.0134399</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.627 sec</td>\n<td>207</td>\n<td>.41E-2</td>\n<td>8430</td>\n<td>1.1695628</td>\n<td>1.5288045</td>\n<td>0.3599716</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.917 sec</td>\n<td>208</td>\n<td>.3E-2</td>\n<td>8430</td>\n<td>1.1694942</td>\n<td>1.7391552</td>\n<td>0.2422446</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:40</td>\n<td>40.108 sec</td>\n<td>209</td>\n<td>.22E-2</td>\n<td>8430</td>\n<td>1.1694213</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>209</td>\n<td>0.4280755</td>\n<td>0.5848479</td>\n<td>0.9391927</td>\n<td>0.2094498</td>\n<td>nan</td>\n<td>nan</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 17 columns]</pre></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-17.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-17 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-17 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-17 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-17 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-17 .h2o-table th,\n#h2o-table-17 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-17 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-17\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>col874</td>\n<td>0.2500748</td>\n<td>1.0</td>\n<td>0.0024913</td></tr>\n<tr><td>col919</td>\n<td>0.2400129</td>\n<td>0.9597644</td>\n<td>0.0023910</td></tr>\n<tr><td>col166</td>\n<td>0.2380715</td>\n<td>0.9520010</td>\n<td>0.0023717</td></tr>\n<tr><td>col862</td>\n<td>0.2356163</td>\n<td>0.9421830</td>\n<td>0.0023472</td></tr>\n<tr><td>col44</td>\n<td>0.2344190</td>\n<td>0.9373954</td>\n<td>0.0023353</td></tr>\n<tr><td>col196</td>\n<td>0.2310739</td>\n<td>0.9240192</td>\n<td>0.0023020</td></tr>\n<tr><td>col877</td>\n<td>0.2308466</td>\n<td>0.9231103</td>\n<td>0.0022997</td></tr>\n<tr><td>col322</td>\n<td>0.2257164</td>\n<td>0.9025955</td>\n<td>0.0022486</td></tr>\n<tr><td>col925</td>\n<td>0.2199686</td>\n<td>0.8796110</td>\n<td>0.0021913</td></tr>\n<tr><td>col184</td>\n<td>0.2173196</td>\n<td>0.8690182</td>\n<td>0.0021650</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>col0</td>\n<td>0.0118955</td>\n<td>0.0475679</td>\n<td>0.0001185</td></tr>\n<tr><td>col392</td>\n<td>0.0116441</td>\n<td>0.0465625</td>\n<td>0.0001160</td></tr>\n<tr><td>col36</td>\n<td>0.0114414</td>\n<td>0.0457518</td>\n<td>0.0001140</td></tr>\n<tr><td>col98</td>\n<td>0.0108436</td>\n<td>0.0433615</td>\n<td>0.0001080</td></tr>\n<tr><td>col740</td>\n<td>0.0107983</td>\n<td>0.0431803</td>\n<td>0.0001076</td></tr>\n<tr><td>col788</td>\n<td>0.0101019</td>\n<td>0.0403954</td>\n<td>0.0001006</td></tr>\n<tr><td>col92</td>\n<td>0.0100254</td>\n<td>0.0400895</td>\n<td>0.0000999</td></tr>\n<tr><td>col39</td>\n<td>0.0097240</td>\n<td>0.0388845</td>\n<td>0.0000969</td></tr>\n<tr><td>col743</td>\n<td>0.0078202</td>\n<td>0.0312714</td>\n<td>0.0000779</td></tr>\n<tr><td>col1298</td>\n<td>0.0073290</td>\n<td>0.0293072</td>\n<td>0.0000730</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[1404 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.load_model('/home/vorkov/Workspace/Emotion-Decetion-Service/learning/GLM_1_AutoML_1_20230909_00442')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T23:11:28.538100331Z",
     "start_time": "2023-09-08T23:11:28.417201700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn. metrics import f1_score\n",
    "\n",
    "pred = aml.predict(test_h2o_frame)\n",
    "pd=h2o.as_list(pred) \n",
    "f1_score(test['col1404'], pd[\"predict\"].tolist(), average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:15:07.267197003Z",
     "start_time": "2023-09-09T01:15:06.946753017Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "24518     sad\n24519     sad\n24520     sad\n24521     sad\n24522     sad\n         ... \n28840    fear\n28841    fear\n28842    fear\n28843    fear\n28844    fear\nName: col1404, Length: 4327, dtype: object"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['col1404']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:18:22.839779910Z",
     "start_time": "2023-09-09T01:18:22.836234508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "['anger',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'neutral',\n 'anger',\n 'neutral',\n 'happy',\n 'contempt',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'neutral',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'contempt',\n 'contempt',\n 'happy',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'contempt',\n 'surprise',\n 'contempt',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'neutral',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'happy',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'happy',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'neutral',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'contempt',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'happy',\n 'contempt',\n 'surprise',\n 'surprise',\n 'neutral',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'neutral',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'happy',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'neutral',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'contempt',\n 'anger',\n 'contempt',\n 'anger',\n 'contempt',\n 'contempt',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'happy',\n 'contempt',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'anger',\n 'contempt',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'neutral',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'neutral',\n 'contempt',\n 'contempt',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'neutral',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'happy',\n 'surprise',\n 'anger',\n 'contempt',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'neutral',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'contempt',\n 'neutral',\n 'anger',\n 'contempt',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'contempt',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'happy',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'contempt',\n 'surprise',\n 'anger',\n 'happy',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'contempt',\n 'neutral',\n 'contempt',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'neutral',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'happy',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'happy',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'surprise',\n 'contempt',\n 'neutral',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'neutral',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'neutral',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'contempt',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'happy',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'anger',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'surprise',\n 'anger',\n 'surprise',\n 'anger',\n 'anger',\n 'contempt',\n 'contempt',\n 'anger',\n 'anger',\n 'anger',\n 'surprise',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'neutral',\n 'happy',\n 'anger',\n 'contempt',\n 'contempt',\n 'contempt',\n 'anger',\n 'surprise',\n 'happy',\n 'anger',\n 'contempt',\n 'contempt',\n 'happy',\n 'surprise',\n 'surprise',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'contempt',\n 'contempt',\n 'anger',\n 'surprise',\n 'surprise',\n 'surprise',\n 'anger',\n 'contempt',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'surprise',\n 'contempt',\n 'surprise',\n 'anger',\n 'anger',\n 'neutral',\n 'contempt',\n 'contempt',\n ...]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd[\"predict\"].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T01:15:52.516723770Z",
     "start_time": "2023-09-09T01:15:52.500325182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
