{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-08T21:03:57.040119996Z",
     "start_time": "2023-09-08T21:03:55.781326998Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas_profiling as pp\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2/landmarks.csv')\n",
    "df.columns = [f'col{i}' for i in range(1405)]\n",
    "df.astype({'col1404':'string'})\n",
    "train, validate, test = np.split(df, [int(.7*len(df)), int(.85*len(df))])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T21:04:06.643089993Z",
     "start_time": "2023-09-08T21:03:57.035913630Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "           col0      col1      col2      col3      col4      col5      col6  \\\n0      0.506777  0.685168 -0.081059  0.508899  0.589536 -0.155494  0.507721   \n1      0.522592  0.728219 -0.069704  0.563158  0.622856 -0.154344  0.532915   \n2      0.507426  0.711682 -0.081520  0.490157  0.622659 -0.162877  0.500488   \n3      0.484002  0.716097 -0.095621  0.490276  0.590272 -0.168015  0.489010   \n4      0.534178  0.709634 -0.044477  0.526397  0.637113 -0.133007  0.526363   \n...         ...       ...       ...       ...       ...       ...       ...   \n20186  0.472416  0.831119 -0.078009  0.433333  0.683983 -0.205998  0.469413   \n20187  0.508826  0.647192 -0.132496  0.508906  0.545129 -0.182883  0.507683   \n20188  0.492575  0.709858 -0.075782  0.496822  0.612935 -0.156433  0.495564   \n20189  0.490839  0.679184 -0.071439  0.517260  0.609654 -0.155441  0.501953   \n20190  0.519303  0.702116 -0.070040  0.535931  0.616246 -0.143221  0.523485   \n\n           col7      col8      col9  ...   col1395   col1396   col1397  \\\n0      0.619720 -0.081626  0.481201  ...  0.547818  0.421041 -0.017888   \n1      0.651415 -0.075771  0.527397  ...  0.563678  0.440509 -0.014150   \n2      0.650763 -0.086197  0.465061  ...  0.549762  0.444901 -0.025063   \n3      0.631962 -0.094333  0.468822  ...  0.548870  0.438363 -0.009491   \n4      0.654088 -0.060292  0.489256  ...  0.537986  0.445891 -0.039478   \n...         ...       ...       ...  ...       ...       ...       ...   \n20186  0.721407 -0.095350  0.418504  ...  0.566312  0.398660 -0.075605   \n20187  0.586804 -0.118799  0.480202  ...  0.558486  0.437194  0.011042   \n20188  0.640419 -0.076693  0.476808  ...  0.555693  0.442941 -0.030559   \n20189  0.631603 -0.078049  0.496043  ...  0.559266  0.452765 -0.026479   \n20190  0.641167 -0.071588  0.506951  ...  0.562500  0.444387 -0.017464   \n\n        col1398   col1399   col1400   col1401   col1402   col1403   col1404  \n0      0.701051  0.395390  0.041529  0.714997  0.388807  0.042386  contempt  \n1      0.693491  0.415474  0.097632  0.706497  0.406117  0.102601  contempt  \n2      0.724568  0.406819  0.017024  0.740692  0.396217  0.016287  contempt  \n3      0.714356  0.434477  0.052216  0.732640  0.424303  0.053430  contempt  \n4      0.672400  0.397646  0.011078  0.682771  0.388529  0.011500  contempt  \n...         ...       ...       ...       ...       ...       ...       ...  \n20186  0.835252  0.338184 -0.069541  0.855527  0.327214 -0.076961     anger  \n20187  0.720975  0.432556  0.079688  0.741551  0.415384  0.083271     anger  \n20188  0.722812  0.415416  0.031063  0.737344  0.407947  0.031359     anger  \n20189  0.708093  0.437545  0.054406  0.723188  0.427620  0.057660     anger  \n20190  0.701819  0.408271  0.060881  0.714420  0.398659  0.062913   disgust  \n\n[20191 rows x 1405 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>col0</th>\n      <th>col1</th>\n      <th>col2</th>\n      <th>col3</th>\n      <th>col4</th>\n      <th>col5</th>\n      <th>col6</th>\n      <th>col7</th>\n      <th>col8</th>\n      <th>col9</th>\n      <th>...</th>\n      <th>col1395</th>\n      <th>col1396</th>\n      <th>col1397</th>\n      <th>col1398</th>\n      <th>col1399</th>\n      <th>col1400</th>\n      <th>col1401</th>\n      <th>col1402</th>\n      <th>col1403</th>\n      <th>col1404</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.506777</td>\n      <td>0.685168</td>\n      <td>-0.081059</td>\n      <td>0.508899</td>\n      <td>0.589536</td>\n      <td>-0.155494</td>\n      <td>0.507721</td>\n      <td>0.619720</td>\n      <td>-0.081626</td>\n      <td>0.481201</td>\n      <td>...</td>\n      <td>0.547818</td>\n      <td>0.421041</td>\n      <td>-0.017888</td>\n      <td>0.701051</td>\n      <td>0.395390</td>\n      <td>0.041529</td>\n      <td>0.714997</td>\n      <td>0.388807</td>\n      <td>0.042386</td>\n      <td>contempt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.522592</td>\n      <td>0.728219</td>\n      <td>-0.069704</td>\n      <td>0.563158</td>\n      <td>0.622856</td>\n      <td>-0.154344</td>\n      <td>0.532915</td>\n      <td>0.651415</td>\n      <td>-0.075771</td>\n      <td>0.527397</td>\n      <td>...</td>\n      <td>0.563678</td>\n      <td>0.440509</td>\n      <td>-0.014150</td>\n      <td>0.693491</td>\n      <td>0.415474</td>\n      <td>0.097632</td>\n      <td>0.706497</td>\n      <td>0.406117</td>\n      <td>0.102601</td>\n      <td>contempt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.507426</td>\n      <td>0.711682</td>\n      <td>-0.081520</td>\n      <td>0.490157</td>\n      <td>0.622659</td>\n      <td>-0.162877</td>\n      <td>0.500488</td>\n      <td>0.650763</td>\n      <td>-0.086197</td>\n      <td>0.465061</td>\n      <td>...</td>\n      <td>0.549762</td>\n      <td>0.444901</td>\n      <td>-0.025063</td>\n      <td>0.724568</td>\n      <td>0.406819</td>\n      <td>0.017024</td>\n      <td>0.740692</td>\n      <td>0.396217</td>\n      <td>0.016287</td>\n      <td>contempt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.484002</td>\n      <td>0.716097</td>\n      <td>-0.095621</td>\n      <td>0.490276</td>\n      <td>0.590272</td>\n      <td>-0.168015</td>\n      <td>0.489010</td>\n      <td>0.631962</td>\n      <td>-0.094333</td>\n      <td>0.468822</td>\n      <td>...</td>\n      <td>0.548870</td>\n      <td>0.438363</td>\n      <td>-0.009491</td>\n      <td>0.714356</td>\n      <td>0.434477</td>\n      <td>0.052216</td>\n      <td>0.732640</td>\n      <td>0.424303</td>\n      <td>0.053430</td>\n      <td>contempt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.534178</td>\n      <td>0.709634</td>\n      <td>-0.044477</td>\n      <td>0.526397</td>\n      <td>0.637113</td>\n      <td>-0.133007</td>\n      <td>0.526363</td>\n      <td>0.654088</td>\n      <td>-0.060292</td>\n      <td>0.489256</td>\n      <td>...</td>\n      <td>0.537986</td>\n      <td>0.445891</td>\n      <td>-0.039478</td>\n      <td>0.672400</td>\n      <td>0.397646</td>\n      <td>0.011078</td>\n      <td>0.682771</td>\n      <td>0.388529</td>\n      <td>0.011500</td>\n      <td>contempt</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20186</th>\n      <td>0.472416</td>\n      <td>0.831119</td>\n      <td>-0.078009</td>\n      <td>0.433333</td>\n      <td>0.683983</td>\n      <td>-0.205998</td>\n      <td>0.469413</td>\n      <td>0.721407</td>\n      <td>-0.095350</td>\n      <td>0.418504</td>\n      <td>...</td>\n      <td>0.566312</td>\n      <td>0.398660</td>\n      <td>-0.075605</td>\n      <td>0.835252</td>\n      <td>0.338184</td>\n      <td>-0.069541</td>\n      <td>0.855527</td>\n      <td>0.327214</td>\n      <td>-0.076961</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>20187</th>\n      <td>0.508826</td>\n      <td>0.647192</td>\n      <td>-0.132496</td>\n      <td>0.508906</td>\n      <td>0.545129</td>\n      <td>-0.182883</td>\n      <td>0.507683</td>\n      <td>0.586804</td>\n      <td>-0.118799</td>\n      <td>0.480202</td>\n      <td>...</td>\n      <td>0.558486</td>\n      <td>0.437194</td>\n      <td>0.011042</td>\n      <td>0.720975</td>\n      <td>0.432556</td>\n      <td>0.079688</td>\n      <td>0.741551</td>\n      <td>0.415384</td>\n      <td>0.083271</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>20188</th>\n      <td>0.492575</td>\n      <td>0.709858</td>\n      <td>-0.075782</td>\n      <td>0.496822</td>\n      <td>0.612935</td>\n      <td>-0.156433</td>\n      <td>0.495564</td>\n      <td>0.640419</td>\n      <td>-0.076693</td>\n      <td>0.476808</td>\n      <td>...</td>\n      <td>0.555693</td>\n      <td>0.442941</td>\n      <td>-0.030559</td>\n      <td>0.722812</td>\n      <td>0.415416</td>\n      <td>0.031063</td>\n      <td>0.737344</td>\n      <td>0.407947</td>\n      <td>0.031359</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>20189</th>\n      <td>0.490839</td>\n      <td>0.679184</td>\n      <td>-0.071439</td>\n      <td>0.517260</td>\n      <td>0.609654</td>\n      <td>-0.155441</td>\n      <td>0.501953</td>\n      <td>0.631603</td>\n      <td>-0.078049</td>\n      <td>0.496043</td>\n      <td>...</td>\n      <td>0.559266</td>\n      <td>0.452765</td>\n      <td>-0.026479</td>\n      <td>0.708093</td>\n      <td>0.437545</td>\n      <td>0.054406</td>\n      <td>0.723188</td>\n      <td>0.427620</td>\n      <td>0.057660</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>20190</th>\n      <td>0.519303</td>\n      <td>0.702116</td>\n      <td>-0.070040</td>\n      <td>0.535931</td>\n      <td>0.616246</td>\n      <td>-0.143221</td>\n      <td>0.523485</td>\n      <td>0.641167</td>\n      <td>-0.071588</td>\n      <td>0.506951</td>\n      <td>...</td>\n      <td>0.562500</td>\n      <td>0.444387</td>\n      <td>-0.017464</td>\n      <td>0.701819</td>\n      <td>0.408271</td>\n      <td>0.060881</td>\n      <td>0.714420</td>\n      <td>0.398659</td>\n      <td>0.062913</td>\n      <td>disgust</td>\n    </tr>\n  </tbody>\n</table>\n<p>20191 rows × 1405 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T21:04:06.671829716Z",
     "start_time": "2023-09-08T21:04:06.639290593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.20.1\" 2023-08-24; OpenJDK Runtime Environment (build 11.0.20.1+1-post-Ubuntu-0ubuntu120.04); OpenJDK 64-Bit Server VM (build 11.0.20.1+1-post-Ubuntu-0ubuntu120.04, mixed mode, sharing)\n",
      "  Starting server from /home/vorkov/Workspace/Emotion-Decetion-Service/venv/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp6l0gx1ws\n",
      "  JVM stdout: /tmp/tmp6l0gx1ws/h2o_vorkov_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp6l0gx1ws/h2o_vorkov_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  -----------------------------\nH2O_cluster_uptime:         01 secs\nH2O_cluster_timezone:       Europe/Moscow\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.42.0.3\nH2O_cluster_version_age:    17 days\nH2O_cluster_name:           H2O_from_python_vorkov_s0lk7n\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    8 Gb\nH2O_cluster_total_cores:    12\nH2O_cluster_allowed_cores:  8\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.8.10 final\n--------------------------  -----------------------------",
      "text/html": "\n<style>\n\n#h2o-table-1.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-1 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-1 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-1 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-1 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-1 .h2o-table th,\n#h2o-table-1 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-1 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-1\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>01 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Moscow</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.42.0.3</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>17 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_vorkov_s0lk7n</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>8 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>12</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.8.10 final</td></tr></tbody>\n  </table>\n</div>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(\n",
    "    nthreads=8,     # number of threads when launching a new H2O server\n",
    "    max_mem_size=8  # in gigabytes\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T21:04:11.414823142Z",
     "start_time": "2023-09-08T21:04:06.664801594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "00:04:42.38: Project: AutoML_1_20230909_00442\n",
      "00:04:42.39: 5-fold cross-validation will be used.\n",
      "00:04:42.40: Setting stopping tolerance adaptively based on the training frame: 0.007037543391537052\n",
      "00:04:42.40: Build control seed: 1\n",
      "00:04:42.42: training frame: Frame key: AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex    cols: 1405    rows: 20191  chunks: 129    size: 239163670  checksum: 7326891014961461210\n",
      "00:04:42.42: validation frame: NULL\n",
      "00:04:42.42: leaderboard frame: NULL\n",
      "00:04:42.42: blending frame: NULL\n",
      "00:04:42.42: response column: col1404\n",
      "00:04:42.42: fold column: null\n",
      "00:04:42.42: weights column: null\n",
      "00:04:42.53: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
      "00:04:42.67: AutoML job created: 2023.09.09 00:04:42.16\n",
      "00:04:42.68: AutoML build started: 2023.09.09 00:04:42.68\n",
      "00:04:42.96: AutoML: starting XGBoost_1_AutoML_1_20230909_00442 model training\n",
      "█████████████\n",
      "00:15:29.476: New leader: XGBoost_1_AutoML_1_20230909_00442, mean_per_class_error: 0.3844254916616668\n",
      "00:15:29.486: AutoML: starting GLM_1_AutoML_1_20230909_00442 model training\n",
      "█████████████████████████████\n",
      "00:44:40.385: New leader: GLM_1_AutoML_1_20230909_00442, mean_per_class_error: 0.35894574967238996\n",
      "00:44:40.396: AutoML: starting GBM_1_AutoML_1_20230909_00442 model training\n",
      "█████████████████████| (done) 100%\n",
      "\n",
      "01:04:45.746: GBM_1_AutoML_1_20230909_00442 [GBM def_5] cancelled\n",
      "01:04:45.747: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}]\n",
      "01:04:45.747: AutoML build stopped: 2023.09.09 01:04:45.747\n",
      "01:04:45.747: AutoML build done: built 2 models\n",
      "01:04:45.747: AutoML duration:  1:00:03.679\n"
     ]
    },
    {
     "data": {
      "text/plain": "Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n\n\nGLM Model: summary\n    family       link         regularization               lambda_search                                                                   number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n--  -----------  -----------  ---------------------------  ------------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  ---------------------------------------------------------------------------------------\n    multinomial  multinomial  Ridge ( lambda = 0.007732 )  nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062  8430                          8424                           205                     AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex\n\nModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2146     420         0          18       46         529         0.320671   1,013 / 3,159\n429      1948        0          47       84         349         0.318166   909 / 2,857\n1        0           0          0        0          0           1          1 / 1\n12       23          0          4407     553        43          0.125248   631 / 5,038\n46       38          0          316      4614       103         0.0982998  503 / 5,117\n383      360         0          104      325        2847        0.291615   1,172 / 4,019\n3017     2789        0          4892     5622       3871        0.20945    4,229 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.79055\n2    0.942301\n3    0.984349\n4    0.997524\n5    0.999851\n6    1\n\nModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2125     436         0          17       46         535         0.327319   1,034 / 3,159\n407      1972        0          46       84         348         0.309765   885 / 2,857\n1        0           0          0        0          0           1          1 / 1\n11       22          0          4405     554        46          0.125645   633 / 5,038\n46       38          0          316      4610       107         0.0990815  507 / 5,117\n389      361         0          100      323        2846        0.291864   1,173 / 4,019\n2979     2829        0          4884     5617       3882        0.209648   4,233 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.790352\n2    0.942152\n3    0.984102\n4    0.997573\n5    0.999852\n6    1\n\nCross-Validation Metrics Summary: \n                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.7906    0.00603916  0.791533      0.795691      0.789004      0.795691      0.78108\nauc                      nan       0           nan           nan           nan           nan           nan\nerr                      0.2094    0.00603916  0.208467      0.204309      0.210996      0.204309      0.21892\nerr_count                845.6     24.3783     842           825           852           825           884\nlogloss                  0.588093  0.0150114   0.601342      0.566701      0.589262      0.58057       0.602593\nmax_per_class_error      0.463815  0.299812    1             0.325949      0.34019       0.330696      0.322242\nmean_per_class_accuracy  0.774628  0.0748648   0.640994      0.812372      0.807228      0.812219      0.800326\nmean_per_class_error     0.225372  0.0748648   0.359006      0.187628      0.192772      0.187781      0.199674\nmse                      0.183476  0.00422378  0.186501      0.17799       0.185417      0.179982      0.187492\nnull_deviance            inf       nan         inf           12781.9       12780.7       12780.7       12780.2\npr_auc                   nan       0           nan           nan           nan           nan           nan\nr2                       0.939117  0.00141633  0.938089      0.94096       0.938478      0.940282      0.937774\nresidual_deviance        4749.72   121.538     4857.82       4576.68       4758.88       4688.68       4866.54\nrmse                     0.428319  0.00494095  0.431858      0.421888      0.430601      0.424242      0.433004\n\nScoring History: \n     timestamp            duration    iteration    lambda    predictors    deviance_train      deviance_xval       deviance_se            alpha    iterations    training_rmse       training_logloss    training_r2         training_classification_error    training_auc    training_pr_auc\n---  -------------------  ----------  -----------  --------  ------------  ------------------  ------------------  ---------------------  -------  ------------  ------------------  ------------------  ------------------  -------------------------------  --------------  -----------------\n     2023-09-09 00:44:00  0.000 sec   5            .22E2     8430          2.248140716119977   5.149931681186062   2.834724413204253      0.0\n     2023-09-09 00:44:00  0.677 sec   8            .16E2     8430          2.1535965161010697  5.0728719149317865  2.8539895652773546     0.0\n     2023-09-09 00:44:01  1.367 sec   12           .12E2     8430          2.062910412015913   2.12673455827772    0.0030129313526652754  0.0\n     2023-09-09 00:44:02  2.145 sec   16           .84E1     8430          1.9758453973316426  2.0371638351436987  0.003449756456666322   0.0\n     2023-09-09 00:44:03  3.117 sec   21           .61E1     8430          1.8925664407633036  1.9516812892231576  0.003938013706845999   0.0\n     2023-09-09 00:44:04  4.269 sec   26           .44E1     8430          1.8151123413826604  1.8703869552280885  0.004312489632431074   0.0\n     2023-09-09 00:44:05  5.408 sec   32           .32E1     8430          1.742629542726998   1.7921155853469783  0.004915638897145258   0.0\n     2023-09-09 00:44:06  6.448 sec   38           .24E1     8430          1.6742460670408088  1.722363487570209   0.005382304566046644   0.0\n     2023-09-09 00:44:07  7.583 sec   44           .17E1     8430          1.605945624848216   1.653229909846932   0.005549571198674038   0.0\n     2023-09-09 00:44:08  8.727 sec   50           .12E1     8430          1.546692054948466   1.5902172649935753  0.006997583138672032   0.0\n---  ---                  ---         ---          ---       ---           ---                 ---                 ---                    ---      ---           ---                 ---                 ---                 ---                              ---             ---\n     2023-09-09 00:44:32  32.010 sec  171          .38E-1    8430          1.2047304117119122  1.219371956915976   0.01171535704375587    0.0\n     2023-09-09 00:44:32  32.307 sec  172          .28E-1    8430          1.2045839758418027  1.2145364839233266  0.010951542185820255   0.0\n     2023-09-09 00:44:38  38.306 sec  201          .2E-1     8430          1.170156009321884   1.2028762552323793  0.007375434935290969   0.0\n     2023-09-09 00:44:38  38.682 sec  203          .15E-1    8430          1.1698353588678703  1.1946579373603106  0.007271888535685163   0.0\n     2023-09-09 00:44:39  38.964 sec  204          .11E-1    8430          1.1697612737323517  1.1861467449604013  0.01424862623234221    0.0\n     2023-09-09 00:44:39  39.151 sec  205          .77E-2    8430          1.1696957862297173  1.1762900748535214  0.01344541482508615    0.0\n     2023-09-09 00:44:39  39.433 sec  206          .56E-2    8430          1.1696321484590473  1.1763251144765063  0.013439865599289018   0.0\n     2023-09-09 00:44:39  39.627 sec  207          .41E-2    8430          1.1695627962171948  1.528804480722551   0.35997155430461053    0.0\n     2023-09-09 00:44:39  39.917 sec  208          .3E-2     8430          1.169494213685578   1.7391552026800745  0.24224461444307635    0.0\n     2023-09-09 00:44:40  40.108 sec  209          .22E-2    8430          1.1694212595229305  0.0                 0.0                    0.0      209           0.4280754520274582  0.5848479289901717  0.9391926917188472  0.2094497548412659               nan             nan\n[30 rows x 17 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance     percentage\n----------  ---------------------  --------------------  ----------------------\ncol874      0.2500748336315155     1.0                   0.002491267590981969\ncol919      0.24001291394233704    0.9597643651579724    0.0023910298578974404\ncol166      0.2380715012550354     0.9520010382405493    0.0023716893331498664\ncol862      0.2356162667274475     0.9421830389963484    0.002347230069824503\ncol44       0.23441898822784424    0.9373953581161225    0.002335302675611632\ncol196      0.23107394576072693    0.9240191921959395    0.002301979066963083\ncol877      0.23084664344787598    0.9231102550208142    0.002299714661236455\ncol322      0.22571641206741333    0.9025954702823307    0.0022486068428814988\ncol925      0.21996857225894928    0.8796109910966583    0.0021913463547906338\ncol184      0.21731959283351898    0.8690182441698181    0.002164956987672323\n---         ---                    ---                   ---\ncol0        0.011895542033016682   0.047567929408461496  0.0001185044409054182\ncol392      0.011644117534160614   0.0465625323630853    0.00011599972783020348\ncol36       0.01144136767834425    0.04575177562730311   0.00011397991585017895\ncol98       0.010843622498214245   0.04336151039569335   0.00010802512554481857\ncol740      0.010798311792314053   0.04318032180809258   0.00010757373628867297\ncol788      0.0101018650457263     0.04039536845443379   0.00010063567225630627\ncol92       0.010025384835898876   0.04008953916039088   9.98737696476843e-05\ncol39       0.00972403772175312    0.03888451141021835   9.687172306744555e-05\ncol743      0.00782020017504692    0.03127144007849251   7.790552519088302e-05\ncol1298     0.007329002022743225   0.029307235423547205  7.301216579196186e-05\n[1404 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-2.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-2 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-2 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-2 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-2 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-2 .h2o-table th,\n#h2o-table-2 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-2 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-2\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>GLM Model: summary</caption>\n    <thead><tr><th></th>\n<th>family</th>\n<th>link</th>\n<th>regularization</th>\n<th>lambda_search</th>\n<th>number_of_predictors_total</th>\n<th>number_of_active_predictors</th>\n<th>number_of_iterations</th>\n<th>training_frame</th></tr></thead>\n    <tbody><tr><td></td>\n<td>multinomial</td>\n<td>multinomial</td>\n<td>Ridge ( lambda = 0.007732 )</td>\n<td>nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062</td>\n<td>8430</td>\n<td>8424</td>\n<td>205</td>\n<td>AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-3.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-3 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-3 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-3 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-3 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-3 .h2o-table th,\n#h2o-table-3 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-3 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-3\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2146.0</td>\n<td>420.0</td>\n<td>0.0</td>\n<td>18.0</td>\n<td>46.0</td>\n<td>529.0</td>\n<td>0.3206711</td>\n<td>1,013 / 3,159</td></tr>\n<tr><td>429.0</td>\n<td>1948.0</td>\n<td>0.0</td>\n<td>47.0</td>\n<td>84.0</td>\n<td>349.0</td>\n<td>0.3181659</td>\n<td>909 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>12.0</td>\n<td>23.0</td>\n<td>0.0</td>\n<td>4407.0</td>\n<td>553.0</td>\n<td>43.0</td>\n<td>0.1252481</td>\n<td>631 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4614.0</td>\n<td>103.0</td>\n<td>0.0982998</td>\n<td>503 / 5,117</td></tr>\n<tr><td>383.0</td>\n<td>360.0</td>\n<td>0.0</td>\n<td>104.0</td>\n<td>325.0</td>\n<td>2847.0</td>\n<td>0.2916148</td>\n<td>1,172 / 4,019</td></tr>\n<tr><td>3017.0</td>\n<td>2789.0</td>\n<td>0.0</td>\n<td>4892.0</td>\n<td>5622.0</td>\n<td>3871.0</td>\n<td>0.2094498</td>\n<td>4,229 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-4.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-4 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-4 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-4 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-4 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-4 .h2o-table th,\n#h2o-table-4 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-4 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-4\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7905502</td></tr>\n<tr><td>2</td>\n<td>0.9423010</td></tr>\n<tr><td>3</td>\n<td>0.9843495</td></tr>\n<tr><td>4</td>\n<td>0.9975237</td></tr>\n<tr><td>5</td>\n<td>0.9998514</td></tr>\n<tr><td>6</td>\n<td>1.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-5.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-5 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-5 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-5 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-5 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-5 .h2o-table th,\n#h2o-table-5 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-5 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-5\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2125.0</td>\n<td>436.0</td>\n<td>0.0</td>\n<td>17.0</td>\n<td>46.0</td>\n<td>535.0</td>\n<td>0.3273188</td>\n<td>1,034 / 3,159</td></tr>\n<tr><td>407.0</td>\n<td>1972.0</td>\n<td>0.0</td>\n<td>46.0</td>\n<td>84.0</td>\n<td>348.0</td>\n<td>0.3097655</td>\n<td>885 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>11.0</td>\n<td>22.0</td>\n<td>0.0</td>\n<td>4405.0</td>\n<td>554.0</td>\n<td>46.0</td>\n<td>0.1256451</td>\n<td>633 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4610.0</td>\n<td>107.0</td>\n<td>0.0990815</td>\n<td>507 / 5,117</td></tr>\n<tr><td>389.0</td>\n<td>361.0</td>\n<td>0.0</td>\n<td>100.0</td>\n<td>323.0</td>\n<td>2846.0</td>\n<td>0.2918636</td>\n<td>1,173 / 4,019</td></tr>\n<tr><td>2979.0</td>\n<td>2829.0</td>\n<td>0.0</td>\n<td>4884.0</td>\n<td>5617.0</td>\n<td>3882.0</td>\n<td>0.2096479</td>\n<td>4,233 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-6.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-6 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-6 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-6 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-6 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-6 .h2o-table th,\n#h2o-table-6 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-6 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-6\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7903522</td></tr>\n<tr><td>2</td>\n<td>0.9421525</td></tr>\n<tr><td>3</td>\n<td>0.9841019</td></tr>\n<tr><td>4</td>\n<td>0.9975733</td></tr>\n<tr><td>5</td>\n<td>0.9998515</td></tr>\n<tr><td>6</td>\n<td>1.0000001</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-7.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-7 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-7 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-7 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-7 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-7 .h2o-table th,\n#h2o-table-7 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-7 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-7\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.7905997</td>\n<td>0.0060392</td>\n<td>0.7915326</td>\n<td>0.7956910</td>\n<td>0.7890044</td>\n<td>0.7956910</td>\n<td>0.7810798</td></tr>\n<tr><td>auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>err</td>\n<td>0.2094003</td>\n<td>0.0060392</td>\n<td>0.2084674</td>\n<td>0.2043091</td>\n<td>0.2109955</td>\n<td>0.2043091</td>\n<td>0.2189203</td></tr>\n<tr><td>err_count</td>\n<td>845.6</td>\n<td>24.37827</td>\n<td>842.0</td>\n<td>825.0</td>\n<td>852.0</td>\n<td>825.0</td>\n<td>884.0</td></tr>\n<tr><td>logloss</td>\n<td>0.5880934</td>\n<td>0.0150114</td>\n<td>0.6013420</td>\n<td>0.5667007</td>\n<td>0.5892617</td>\n<td>0.5805697</td>\n<td>0.6025928</td></tr>\n<tr><td>max_per_class_error</td>\n<td>0.4638154</td>\n<td>0.2998116</td>\n<td>1.0</td>\n<td>0.3259494</td>\n<td>0.3401899</td>\n<td>0.3306962</td>\n<td>0.3222417</td></tr>\n<tr><td>mean_per_class_accuracy</td>\n<td>0.7746276</td>\n<td>0.0748648</td>\n<td>0.6409936</td>\n<td>0.812372</td>\n<td>0.8072276</td>\n<td>0.8122187</td>\n<td>0.8003262</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.2253724</td>\n<td>0.0748648</td>\n<td>0.3590064</td>\n<td>0.1876280</td>\n<td>0.1927724</td>\n<td>0.1877813</td>\n<td>0.1996739</td></tr>\n<tr><td>mse</td>\n<td>0.1834765</td>\n<td>0.0042238</td>\n<td>0.1865014</td>\n<td>0.1779897</td>\n<td>0.1854174</td>\n<td>0.1799816</td>\n<td>0.1874921</td></tr>\n<tr><td>null_deviance</td>\n<td>inf</td>\n<td>nan</td>\n<td>inf</td>\n<td>12781.859</td>\n<td>12780.725</td>\n<td>12780.725</td>\n<td>12780.242</td></tr>\n<tr><td>pr_auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>r2</td>\n<td>0.9391168</td>\n<td>0.0014163</td>\n<td>0.9380893</td>\n<td>0.9409605</td>\n<td>0.9384785</td>\n<td>0.9402820</td>\n<td>0.9377737</td></tr>\n<tr><td>residual_deviance</td>\n<td>4749.718</td>\n<td>121.53792</td>\n<td>4857.817</td>\n<td>4576.675</td>\n<td>4758.8774</td>\n<td>4688.681</td>\n<td>4866.5396</td></tr>\n<tr><td>rmse</td>\n<td>0.4283187</td>\n<td>0.0049410</td>\n<td>0.4318581</td>\n<td>0.4218883</td>\n<td>0.4306012</td>\n<td>0.4242424</td>\n<td>0.4330036</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-8.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-8 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-8 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-8 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-8 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-8 .h2o-table th,\n#h2o-table-8 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-8 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-8\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>iteration</th>\n<th>lambda</th>\n<th>predictors</th>\n<th>deviance_train</th>\n<th>deviance_xval</th>\n<th>deviance_se</th>\n<th>alpha</th>\n<th>iterations</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_r2</th>\n<th>training_classification_error</th>\n<th>training_auc</th>\n<th>training_pr_auc</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.000 sec</td>\n<td>5</td>\n<td>.22E2</td>\n<td>8430</td>\n<td>2.2481407</td>\n<td>5.1499317</td>\n<td>2.8347244</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.677 sec</td>\n<td>8</td>\n<td>.16E2</td>\n<td>8430</td>\n<td>2.1535965</td>\n<td>5.0728719</td>\n<td>2.8539896</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:01</td>\n<td> 1.367 sec</td>\n<td>12</td>\n<td>.12E2</td>\n<td>8430</td>\n<td>2.0629104</td>\n<td>2.1267346</td>\n<td>0.0030129</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:02</td>\n<td> 2.145 sec</td>\n<td>16</td>\n<td>.84E1</td>\n<td>8430</td>\n<td>1.9758454</td>\n<td>2.0371638</td>\n<td>0.0034498</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:03</td>\n<td> 3.117 sec</td>\n<td>21</td>\n<td>.61E1</td>\n<td>8430</td>\n<td>1.8925664</td>\n<td>1.9516813</td>\n<td>0.0039380</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:04</td>\n<td> 4.269 sec</td>\n<td>26</td>\n<td>.44E1</td>\n<td>8430</td>\n<td>1.8151123</td>\n<td>1.8703870</td>\n<td>0.0043125</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:05</td>\n<td> 5.408 sec</td>\n<td>32</td>\n<td>.32E1</td>\n<td>8430</td>\n<td>1.7426295</td>\n<td>1.7921156</td>\n<td>0.0049156</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:06</td>\n<td> 6.448 sec</td>\n<td>38</td>\n<td>.24E1</td>\n<td>8430</td>\n<td>1.6742461</td>\n<td>1.7223635</td>\n<td>0.0053823</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:07</td>\n<td> 7.583 sec</td>\n<td>44</td>\n<td>.17E1</td>\n<td>8430</td>\n<td>1.6059456</td>\n<td>1.6532299</td>\n<td>0.0055496</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:08</td>\n<td> 8.727 sec</td>\n<td>50</td>\n<td>.12E1</td>\n<td>8430</td>\n<td>1.5466921</td>\n<td>1.5902173</td>\n<td>0.0069976</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.010 sec</td>\n<td>171</td>\n<td>.38E-1</td>\n<td>8430</td>\n<td>1.2047304</td>\n<td>1.2193720</td>\n<td>0.0117154</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.307 sec</td>\n<td>172</td>\n<td>.28E-1</td>\n<td>8430</td>\n<td>1.2045840</td>\n<td>1.2145365</td>\n<td>0.0109515</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.306 sec</td>\n<td>201</td>\n<td>.2E-1</td>\n<td>8430</td>\n<td>1.1701560</td>\n<td>1.2028763</td>\n<td>0.0073754</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.682 sec</td>\n<td>203</td>\n<td>.15E-1</td>\n<td>8430</td>\n<td>1.1698354</td>\n<td>1.1946579</td>\n<td>0.0072719</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>38.964 sec</td>\n<td>204</td>\n<td>.11E-1</td>\n<td>8430</td>\n<td>1.1697613</td>\n<td>1.1861467</td>\n<td>0.0142486</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.151 sec</td>\n<td>205</td>\n<td>.77E-2</td>\n<td>8430</td>\n<td>1.1696958</td>\n<td>1.1762901</td>\n<td>0.0134454</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.433 sec</td>\n<td>206</td>\n<td>.56E-2</td>\n<td>8430</td>\n<td>1.1696321</td>\n<td>1.1763251</td>\n<td>0.0134399</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.627 sec</td>\n<td>207</td>\n<td>.41E-2</td>\n<td>8430</td>\n<td>1.1695628</td>\n<td>1.5288045</td>\n<td>0.3599716</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.917 sec</td>\n<td>208</td>\n<td>.3E-2</td>\n<td>8430</td>\n<td>1.1694942</td>\n<td>1.7391552</td>\n<td>0.2422446</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:40</td>\n<td>40.108 sec</td>\n<td>209</td>\n<td>.22E-2</td>\n<td>8430</td>\n<td>1.1694213</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>209</td>\n<td>0.4280755</td>\n<td>0.5848479</td>\n<td>0.9391927</td>\n<td>0.2094498</td>\n<td>nan</td>\n<td>nan</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 17 columns]</pre></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-9.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-9 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-9 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-9 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-9 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-9 .h2o-table th,\n#h2o-table-9 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-9 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-9\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>col874</td>\n<td>0.2500748</td>\n<td>1.0</td>\n<td>0.0024913</td></tr>\n<tr><td>col919</td>\n<td>0.2400129</td>\n<td>0.9597644</td>\n<td>0.0023910</td></tr>\n<tr><td>col166</td>\n<td>0.2380715</td>\n<td>0.9520010</td>\n<td>0.0023717</td></tr>\n<tr><td>col862</td>\n<td>0.2356163</td>\n<td>0.9421830</td>\n<td>0.0023472</td></tr>\n<tr><td>col44</td>\n<td>0.2344190</td>\n<td>0.9373954</td>\n<td>0.0023353</td></tr>\n<tr><td>col196</td>\n<td>0.2310739</td>\n<td>0.9240192</td>\n<td>0.0023020</td></tr>\n<tr><td>col877</td>\n<td>0.2308466</td>\n<td>0.9231103</td>\n<td>0.0022997</td></tr>\n<tr><td>col322</td>\n<td>0.2257164</td>\n<td>0.9025955</td>\n<td>0.0022486</td></tr>\n<tr><td>col925</td>\n<td>0.2199686</td>\n<td>0.8796110</td>\n<td>0.0021913</td></tr>\n<tr><td>col184</td>\n<td>0.2173196</td>\n<td>0.8690182</td>\n<td>0.0021650</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>col0</td>\n<td>0.0118955</td>\n<td>0.0475679</td>\n<td>0.0001185</td></tr>\n<tr><td>col392</td>\n<td>0.0116441</td>\n<td>0.0465625</td>\n<td>0.0001160</td></tr>\n<tr><td>col36</td>\n<td>0.0114414</td>\n<td>0.0457518</td>\n<td>0.0001140</td></tr>\n<tr><td>col98</td>\n<td>0.0108436</td>\n<td>0.0433615</td>\n<td>0.0001080</td></tr>\n<tr><td>col740</td>\n<td>0.0107983</td>\n<td>0.0431803</td>\n<td>0.0001076</td></tr>\n<tr><td>col788</td>\n<td>0.0101019</td>\n<td>0.0403954</td>\n<td>0.0001006</td></tr>\n<tr><td>col92</td>\n<td>0.0100254</td>\n<td>0.0400895</td>\n<td>0.0000999</td></tr>\n<tr><td>col39</td>\n<td>0.0097240</td>\n<td>0.0388845</td>\n<td>0.0000969</td></tr>\n<tr><td>col743</td>\n<td>0.0078202</td>\n<td>0.0312714</td>\n<td>0.0000779</td></tr>\n<tr><td>col1298</td>\n<td>0.0073290</td>\n<td>0.0293072</td>\n<td>0.0000730</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[1404 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_h2o_frame = h2o.H2OFrame(train)\n",
    "test_h2o_frame = h2o.H2OFrame(test)\n",
    "\n",
    "x = train_h2o_frame.columns\n",
    "y = \"col1404\"\n",
    "x.remove(y)\n",
    "\n",
    "aml = H2OAutoML(max_models=8, seed=1, max_runtime_secs=60*60, verbosity='info')\n",
    "aml.train(x=x, y=y, training_frame=train_h2o_frame)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T22:04:47.101299573Z",
     "start_time": "2023-09-08T21:04:11.893407138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'AUTO'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "model_id                             mean_per_class_error    logloss      rmse       mse\n---------------------------------  ----------------------  ---------  --------  --------\nGLM_1_AutoML_1_20230909_00442                    0.358946   0.588139  0.428383  0.183512\nXGBoost_1_AutoML_1_20230909_00442                0.384425   0.629443  0.435483  0.189645\n[2 rows x 5 columns]\n",
      "text/html": "<table class='dataframe'>\n<thead>\n<tr><th>model_id                         </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n</thead>\n<tbody>\n<tr><td>GLM_1_AutoML_1_20230909_00442    </td><td style=\"text-align: right;\">              0.358946</td><td style=\"text-align: right;\"> 0.588139</td><td style=\"text-align: right;\">0.428383</td><td style=\"text-align: right;\">0.183512</td></tr>\n<tr><td>XGBoost_1_AutoML_1_20230909_00442</td><td style=\"text-align: right;\">              0.384425</td><td style=\"text-align: right;\"> 0.629443</td><td style=\"text-align: right;\">0.435483</td><td style=\"text-align: right;\">0.189645</td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[2 rows x 5 columns]</pre>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T22:27:45.900360690Z",
     "start_time": "2023-09-08T22:27:45.857681608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test_h2o_frame = test_h2o_frame.drop('col1404')\n",
    "pred = aml.predict(test_h2o_frame)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T22:29:58.810267257Z",
     "start_time": "2023-09-08T22:29:58.487689609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "predict       anger    contempt      disgust        happy      neutral    surprise\n---------  --------  ----------  -----------  -----------  -----------  ----------\nanger      0.785474  0.00315324  7.16687e-07  0.000155655  2.75566e-06  0.211214\nanger      0.513401  0.224812    1.63442e-05  7.30381e-05  0.00407176   0.257626\nanger      0.915206  0.0457143   4.95148e-06  1.73313e-05  0.0040324    0.0350254\nanger      0.858818  0.00353934  1.40306e-06  3.76374e-05  1.14827e-05  0.137592\ncontempt   0.260427  0.48689     2.40392e-05  0.00255855   0.0118256    0.238274\nanger      0.732838  0.091804    1.497e-05    7.53426e-05  0.0174777    0.15779\nanger      0.828043  0.0637554   3.51999e-07  3.13452e-07  0.000490878  0.10771\nanger      0.889751  0.106978    2.23184e-06  5.22006e-05  4.08157e-05  0.00317531\nanger      0.56497   0.178844    7.34457e-06  0.000578934  0.038937     0.216663\nanger      0.326414  0.152872    5.89797e-05  0.00278635   0.19269      0.325179\n[4327 rows x 7 columns]\n",
      "text/html": "<table class='dataframe'>\n<thead>\n<tr><th>predict  </th><th style=\"text-align: right;\">   anger</th><th style=\"text-align: right;\">  contempt</th><th style=\"text-align: right;\">    disgust</th><th style=\"text-align: right;\">      happy</th><th style=\"text-align: right;\">    neutral</th><th style=\"text-align: right;\">  surprise</th></tr>\n</thead>\n<tbody>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.785474</td><td style=\"text-align: right;\">0.00315324</td><td style=\"text-align: right;\">7.16687e-07</td><td style=\"text-align: right;\">0.000155655</td><td style=\"text-align: right;\">2.75566e-06</td><td style=\"text-align: right;\">0.211214  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.513401</td><td style=\"text-align: right;\">0.224812  </td><td style=\"text-align: right;\">1.63442e-05</td><td style=\"text-align: right;\">7.30381e-05</td><td style=\"text-align: right;\">0.00407176 </td><td style=\"text-align: right;\">0.257626  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.915206</td><td style=\"text-align: right;\">0.0457143 </td><td style=\"text-align: right;\">4.95148e-06</td><td style=\"text-align: right;\">1.73313e-05</td><td style=\"text-align: right;\">0.0040324  </td><td style=\"text-align: right;\">0.0350254 </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.858818</td><td style=\"text-align: right;\">0.00353934</td><td style=\"text-align: right;\">1.40306e-06</td><td style=\"text-align: right;\">3.76374e-05</td><td style=\"text-align: right;\">1.14827e-05</td><td style=\"text-align: right;\">0.137592  </td></tr>\n<tr><td>contempt </td><td style=\"text-align: right;\">0.260427</td><td style=\"text-align: right;\">0.48689   </td><td style=\"text-align: right;\">2.40392e-05</td><td style=\"text-align: right;\">0.00255855 </td><td style=\"text-align: right;\">0.0118256  </td><td style=\"text-align: right;\">0.238274  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.732838</td><td style=\"text-align: right;\">0.091804  </td><td style=\"text-align: right;\">1.497e-05  </td><td style=\"text-align: right;\">7.53426e-05</td><td style=\"text-align: right;\">0.0174777  </td><td style=\"text-align: right;\">0.15779   </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.828043</td><td style=\"text-align: right;\">0.0637554 </td><td style=\"text-align: right;\">3.51999e-07</td><td style=\"text-align: right;\">3.13452e-07</td><td style=\"text-align: right;\">0.000490878</td><td style=\"text-align: right;\">0.10771   </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.889751</td><td style=\"text-align: right;\">0.106978  </td><td style=\"text-align: right;\">2.23184e-06</td><td style=\"text-align: right;\">5.22006e-05</td><td style=\"text-align: right;\">4.08157e-05</td><td style=\"text-align: right;\">0.00317531</td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.56497 </td><td style=\"text-align: right;\">0.178844  </td><td style=\"text-align: right;\">7.34457e-06</td><td style=\"text-align: right;\">0.000578934</td><td style=\"text-align: right;\">0.038937   </td><td style=\"text-align: right;\">0.216663  </td></tr>\n<tr><td>anger    </td><td style=\"text-align: right;\">0.326414</td><td style=\"text-align: right;\">0.152872  </td><td style=\"text-align: right;\">5.89797e-05</td><td style=\"text-align: right;\">0.00278635 </td><td style=\"text-align: right;\">0.19269    </td><td style=\"text-align: right;\">0.325179  </td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[4327 rows x 7 columns]</pre>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T22:30:23.279191708Z",
     "start_time": "2023-09-08T22:30:23.253532970Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "best_model = aml.leader\n",
    "# aml.score(test_h2o_frame, test_h2o_frame.MEDV)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T23:09:12.980013251Z",
     "start_time": "2023-09-08T23:09:12.930294802Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/vorkov/Workspace/Emotion-Decetion-Service/learning/GLM_1_AutoML_1_20230909_00442'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(model=best_model, path=\"./\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T23:10:54.141881800Z",
     "start_time": "2023-09-08T23:10:54.129884200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n\n\nGLM Model: summary\n    family       link         regularization               lambda_search                                                                   number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n--  -----------  -----------  ---------------------------  ------------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  ---------------------------------------------------------------------------------------\n    multinomial  multinomial  Ridge ( lambda = 0.007732 )  nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062  8430                          8424                           205                     AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex\n\nModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2146     420         0          18       46         529         0.320671   1,013 / 3,159\n429      1948        0          47       84         349         0.318166   909 / 2,857\n1        0           0          0        0          0           1          1 / 1\n12       23          0          4407     553        43          0.125248   631 / 5,038\n46       38          0          316      4614       103         0.0982998  503 / 5,117\n383      360         0          104      325        2847        0.291615   1,172 / 4,019\n3017     2789        0          4892     5622       3871        0.20945    4,229 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.79055\n2    0.942301\n3    0.984349\n4    0.997524\n5    0.999851\n6    1\n\nModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\nanger    contempt    disgust    happy    neutral    surprise    Error      Rate\n-------  ----------  ---------  -------  ---------  ----------  ---------  --------------\n2125     436         0          17       46         535         0.327319   1,034 / 3,159\n407      1972        0          46       84         348         0.309765   885 / 2,857\n1        0           0          0        0          0           1          1 / 1\n11       22          0          4405     554        46          0.125645   633 / 5,038\n46       38          0          316      4610       107         0.0990815  507 / 5,117\n389      361         0          100      323        2846        0.291864   1,173 / 4,019\n2979     2829        0          4884     5617       3882        0.209648   4,233 / 20,191\n\nTop-6 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.790352\n2    0.942152\n3    0.984102\n4    0.997573\n5    0.999852\n6    1\n\nCross-Validation Metrics Summary: \n                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  --------  ----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.7906    0.00603916  0.791533      0.795691      0.789004      0.795691      0.78108\nauc                      nan       0           nan           nan           nan           nan           nan\nerr                      0.2094    0.00603916  0.208467      0.204309      0.210996      0.204309      0.21892\nerr_count                845.6     24.3783     842           825           852           825           884\nlogloss                  0.588093  0.0150114   0.601342      0.566701      0.589262      0.58057       0.602593\nmax_per_class_error      0.463815  0.299812    1             0.325949      0.34019       0.330696      0.322242\nmean_per_class_accuracy  0.774628  0.0748648   0.640994      0.812372      0.807228      0.812219      0.800326\nmean_per_class_error     0.225372  0.0748648   0.359006      0.187628      0.192772      0.187781      0.199674\nmse                      0.183476  0.00422378  0.186501      0.17799       0.185417      0.179982      0.187492\nnull_deviance            inf       nan         inf           12781.9       12780.7       12780.7       12780.2\npr_auc                   nan       0           nan           nan           nan           nan           nan\nr2                       0.939117  0.00141633  0.938089      0.94096       0.938478      0.940282      0.937774\nresidual_deviance        4749.72   121.538     4857.82       4576.68       4758.88       4688.68       4866.54\nrmse                     0.428319  0.00494095  0.431858      0.421888      0.430601      0.424242      0.433004\n\nScoring History: \n     timestamp            duration    iteration    lambda    predictors    deviance_train      deviance_xval       deviance_se            alpha    iterations    training_rmse       training_logloss    training_r2         training_classification_error    training_auc    training_pr_auc\n---  -------------------  ----------  -----------  --------  ------------  ------------------  ------------------  ---------------------  -------  ------------  ------------------  ------------------  ------------------  -------------------------------  --------------  -----------------\n     2023-09-09 00:44:00  0.000 sec   5            .22E2     8430          2.248140716119977   5.149931681186062   2.834724413204253      0.0\n     2023-09-09 00:44:00  0.677 sec   8            .16E2     8430          2.1535965161010697  5.0728719149317865  2.8539895652773546     0.0\n     2023-09-09 00:44:01  1.367 sec   12           .12E2     8430          2.062910412015913   2.12673455827772    0.0030129313526652754  0.0\n     2023-09-09 00:44:02  2.145 sec   16           .84E1     8430          1.9758453973316426  2.0371638351436987  0.003449756456666322   0.0\n     2023-09-09 00:44:03  3.117 sec   21           .61E1     8430          1.8925664407633036  1.9516812892231576  0.003938013706845999   0.0\n     2023-09-09 00:44:04  4.269 sec   26           .44E1     8430          1.8151123413826604  1.8703869552280885  0.004312489632431074   0.0\n     2023-09-09 00:44:05  5.408 sec   32           .32E1     8430          1.742629542726998   1.7921155853469783  0.004915638897145258   0.0\n     2023-09-09 00:44:06  6.448 sec   38           .24E1     8430          1.6742460670408088  1.722363487570209   0.005382304566046644   0.0\n     2023-09-09 00:44:07  7.583 sec   44           .17E1     8430          1.605945624848216   1.653229909846932   0.005549571198674038   0.0\n     2023-09-09 00:44:08  8.727 sec   50           .12E1     8430          1.546692054948466   1.5902172649935753  0.006997583138672032   0.0\n---  ---                  ---         ---          ---       ---           ---                 ---                 ---                    ---      ---           ---                 ---                 ---                 ---                              ---             ---\n     2023-09-09 00:44:32  32.010 sec  171          .38E-1    8430          1.2047304117119122  1.219371956915976   0.01171535704375587    0.0\n     2023-09-09 00:44:32  32.307 sec  172          .28E-1    8430          1.2045839758418027  1.2145364839233266  0.010951542185820255   0.0\n     2023-09-09 00:44:38  38.306 sec  201          .2E-1     8430          1.170156009321884   1.2028762552323793  0.007375434935290969   0.0\n     2023-09-09 00:44:38  38.682 sec  203          .15E-1    8430          1.1698353588678703  1.1946579373603106  0.007271888535685163   0.0\n     2023-09-09 00:44:39  38.964 sec  204          .11E-1    8430          1.1697612737323517  1.1861467449604013  0.01424862623234221    0.0\n     2023-09-09 00:44:39  39.151 sec  205          .77E-2    8430          1.1696957862297173  1.1762900748535214  0.01344541482508615    0.0\n     2023-09-09 00:44:39  39.433 sec  206          .56E-2    8430          1.1696321484590473  1.1763251144765063  0.013439865599289018   0.0\n     2023-09-09 00:44:39  39.627 sec  207          .41E-2    8430          1.1695627962171948  1.528804480722551   0.35997155430461053    0.0\n     2023-09-09 00:44:39  39.917 sec  208          .3E-2     8430          1.169494213685578   1.7391552026800745  0.24224461444307635    0.0\n     2023-09-09 00:44:40  40.108 sec  209          .22E-2    8430          1.1694212595229305  0.0                 0.0                    0.0      209           0.4280754520274582  0.5848479289901717  0.9391926917188472  0.2094497548412659               nan             nan\n[30 rows x 17 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance     percentage\n----------  ---------------------  --------------------  ----------------------\ncol874      0.2500748336315155     1.0                   0.002491267590981969\ncol919      0.24001291394233704    0.9597643651579724    0.0023910298578974404\ncol166      0.2380715012550354     0.9520010382405493    0.0023716893331498664\ncol862      0.2356162667274475     0.9421830389963484    0.002347230069824503\ncol44       0.23441898822784424    0.9373953581161225    0.002335302675611632\ncol196      0.23107394576072693    0.9240191921959395    0.002301979066963083\ncol877      0.23084664344787598    0.9231102550208142    0.002299714661236455\ncol322      0.22571641206741333    0.9025954702823307    0.0022486068428814988\ncol925      0.21996857225894928    0.8796109910966583    0.0021913463547906338\ncol184      0.21731959283351898    0.8690182441698181    0.002164956987672323\n---         ---                    ---                   ---\ncol0        0.011895542033016682   0.047567929408461496  0.0001185044409054182\ncol392      0.011644117534160614   0.0465625323630853    0.00011599972783020348\ncol36       0.01144136767834425    0.04575177562730311   0.00011397991585017895\ncol98       0.010843622498214245   0.04336151039569335   0.00010802512554481857\ncol740      0.010798311792314053   0.04318032180809258   0.00010757373628867297\ncol788      0.0101018650457263     0.04039536845443379   0.00010063567225630627\ncol92       0.010025384835898876   0.04008953916039088   9.98737696476843e-05\ncol39       0.00972403772175312    0.03888451141021835   9.687172306744555e-05\ncol743      0.00782020017504692    0.03127144007849251   7.790552519088302e-05\ncol1298     0.007329002022743225   0.029307235423547205  7.301216579196186e-05\n[1404 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.",
      "text/html": "<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGeneralizedLinearEstimator : Generalized Linear Modeling\nModel Key: GLM_1_AutoML_1_20230909_00442\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-10.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-10 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-10 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-10 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-10 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-10 .h2o-table th,\n#h2o-table-10 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-10 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-10\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>GLM Model: summary</caption>\n    <thead><tr><th></th>\n<th>family</th>\n<th>link</th>\n<th>regularization</th>\n<th>lambda_search</th>\n<th>number_of_predictors_total</th>\n<th>number_of_active_predictors</th>\n<th>number_of_iterations</th>\n<th>training_frame</th></tr></thead>\n    <tbody><tr><td></td>\n<td>multinomial</td>\n<td>multinomial</td>\n<td>Ridge ( lambda = 0.007732 )</td>\n<td>nlambda = 30, lambda.max = 21.707, lambda.min = 0.007732, lambda.1se = 0.01062</td>\n<td>8430</td>\n<td>8424</td>\n<td>205</td>\n<td>AutoML_1_20230909_00442_training_Key_Frame__upload_9b0ad4f7d1eb0254f20700a6c8f745c0.hex</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on train data. **\n\nMSE: 0.1832485926285127\nRMSE: 0.4280754520274582\nLogLoss: 0.5848479289901717\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: 63923.76920676409\nResidual deviance: 23617.327619764204\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-11.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-11 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-11 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-11 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-11 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-11 .h2o-table th,\n#h2o-table-11 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-11 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-11\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2146.0</td>\n<td>420.0</td>\n<td>0.0</td>\n<td>18.0</td>\n<td>46.0</td>\n<td>529.0</td>\n<td>0.3206711</td>\n<td>1,013 / 3,159</td></tr>\n<tr><td>429.0</td>\n<td>1948.0</td>\n<td>0.0</td>\n<td>47.0</td>\n<td>84.0</td>\n<td>349.0</td>\n<td>0.3181659</td>\n<td>909 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>12.0</td>\n<td>23.0</td>\n<td>0.0</td>\n<td>4407.0</td>\n<td>553.0</td>\n<td>43.0</td>\n<td>0.1252481</td>\n<td>631 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4614.0</td>\n<td>103.0</td>\n<td>0.0982998</td>\n<td>503 / 5,117</td></tr>\n<tr><td>383.0</td>\n<td>360.0</td>\n<td>0.0</td>\n<td>104.0</td>\n<td>325.0</td>\n<td>2847.0</td>\n<td>0.2916148</td>\n<td>1,172 / 4,019</td></tr>\n<tr><td>3017.0</td>\n<td>2789.0</td>\n<td>0.0</td>\n<td>4892.0</td>\n<td>5622.0</td>\n<td>3871.0</td>\n<td>0.2094498</td>\n<td>4,229 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-12.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-12 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-12 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-12 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-12 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-12 .h2o-table th,\n#h2o-table-12 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-12 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-12\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7905502</td></tr>\n<tr><td>2</td>\n<td>0.9423010</td></tr>\n<tr><td>3</td>\n<td>0.9843495</td></tr>\n<tr><td>4</td>\n<td>0.9975237</td></tr>\n<tr><td>5</td>\n<td>0.9998514</td></tr>\n<tr><td>6</td>\n<td>1.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsMultinomialGLM: glm\n** Reported on cross-validation data. **\n\nMSE: 0.18351216993959682\nRMSE: 0.42838320454891415\nLogLoss: 0.588139110499819\nNull degrees of freedom: 20190\nResidual degrees of freedom: 11761\nNull deviance: Infinity\nResidual deviance: 23750.499560828222\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-13.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-13 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-13 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-13 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-13 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-13 .h2o-table th,\n#h2o-table-13 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-13 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-13\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix: Row labels: Actual class; Column labels: Predicted class</caption>\n    <thead><tr><th>anger</th>\n<th>contempt</th>\n<th>disgust</th>\n<th>happy</th>\n<th>neutral</th>\n<th>surprise</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>2125.0</td>\n<td>436.0</td>\n<td>0.0</td>\n<td>17.0</td>\n<td>46.0</td>\n<td>535.0</td>\n<td>0.3273188</td>\n<td>1,034 / 3,159</td></tr>\n<tr><td>407.0</td>\n<td>1972.0</td>\n<td>0.0</td>\n<td>46.0</td>\n<td>84.0</td>\n<td>348.0</td>\n<td>0.3097655</td>\n<td>885 / 2,857</td></tr>\n<tr><td>1.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1 / 1</td></tr>\n<tr><td>11.0</td>\n<td>22.0</td>\n<td>0.0</td>\n<td>4405.0</td>\n<td>554.0</td>\n<td>46.0</td>\n<td>0.1256451</td>\n<td>633 / 5,038</td></tr>\n<tr><td>46.0</td>\n<td>38.0</td>\n<td>0.0</td>\n<td>316.0</td>\n<td>4610.0</td>\n<td>107.0</td>\n<td>0.0990815</td>\n<td>507 / 5,117</td></tr>\n<tr><td>389.0</td>\n<td>361.0</td>\n<td>0.0</td>\n<td>100.0</td>\n<td>323.0</td>\n<td>2846.0</td>\n<td>0.2918636</td>\n<td>1,173 / 4,019</td></tr>\n<tr><td>2979.0</td>\n<td>2829.0</td>\n<td>0.0</td>\n<td>4884.0</td>\n<td>5617.0</td>\n<td>3882.0</td>\n<td>0.2096479</td>\n<td>4,233 / 20,191</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-14.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-14 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-14 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-14 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-14 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-14 .h2o-table th,\n#h2o-table-14 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-14 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-14\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Top-6 Hit Ratios: </caption>\n    <thead><tr><th>k</th>\n<th>hit_ratio</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.7903522</td></tr>\n<tr><td>2</td>\n<td>0.9421525</td></tr>\n<tr><td>3</td>\n<td>0.9841019</td></tr>\n<tr><td>4</td>\n<td>0.9975733</td></tr>\n<tr><td>5</td>\n<td>0.9998515</td></tr>\n<tr><td>6</td>\n<td>1.0000001</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-15.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-15 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-15 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-15 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-15 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-15 .h2o-table th,\n#h2o-table-15 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-15 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-15\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.7905997</td>\n<td>0.0060392</td>\n<td>0.7915326</td>\n<td>0.7956910</td>\n<td>0.7890044</td>\n<td>0.7956910</td>\n<td>0.7810798</td></tr>\n<tr><td>auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>err</td>\n<td>0.2094003</td>\n<td>0.0060392</td>\n<td>0.2084674</td>\n<td>0.2043091</td>\n<td>0.2109955</td>\n<td>0.2043091</td>\n<td>0.2189203</td></tr>\n<tr><td>err_count</td>\n<td>845.6</td>\n<td>24.37827</td>\n<td>842.0</td>\n<td>825.0</td>\n<td>852.0</td>\n<td>825.0</td>\n<td>884.0</td></tr>\n<tr><td>logloss</td>\n<td>0.5880934</td>\n<td>0.0150114</td>\n<td>0.6013420</td>\n<td>0.5667007</td>\n<td>0.5892617</td>\n<td>0.5805697</td>\n<td>0.6025928</td></tr>\n<tr><td>max_per_class_error</td>\n<td>0.4638154</td>\n<td>0.2998116</td>\n<td>1.0</td>\n<td>0.3259494</td>\n<td>0.3401899</td>\n<td>0.3306962</td>\n<td>0.3222417</td></tr>\n<tr><td>mean_per_class_accuracy</td>\n<td>0.7746276</td>\n<td>0.0748648</td>\n<td>0.6409936</td>\n<td>0.812372</td>\n<td>0.8072276</td>\n<td>0.8122187</td>\n<td>0.8003262</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.2253724</td>\n<td>0.0748648</td>\n<td>0.3590064</td>\n<td>0.1876280</td>\n<td>0.1927724</td>\n<td>0.1877813</td>\n<td>0.1996739</td></tr>\n<tr><td>mse</td>\n<td>0.1834765</td>\n<td>0.0042238</td>\n<td>0.1865014</td>\n<td>0.1779897</td>\n<td>0.1854174</td>\n<td>0.1799816</td>\n<td>0.1874921</td></tr>\n<tr><td>null_deviance</td>\n<td>inf</td>\n<td>nan</td>\n<td>inf</td>\n<td>12781.859</td>\n<td>12780.725</td>\n<td>12780.725</td>\n<td>12780.242</td></tr>\n<tr><td>pr_auc</td>\n<td>nan</td>\n<td>0.0</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td>\n<td>nan</td></tr>\n<tr><td>r2</td>\n<td>0.9391168</td>\n<td>0.0014163</td>\n<td>0.9380893</td>\n<td>0.9409605</td>\n<td>0.9384785</td>\n<td>0.9402820</td>\n<td>0.9377737</td></tr>\n<tr><td>residual_deviance</td>\n<td>4749.718</td>\n<td>121.53792</td>\n<td>4857.817</td>\n<td>4576.675</td>\n<td>4758.8774</td>\n<td>4688.681</td>\n<td>4866.5396</td></tr>\n<tr><td>rmse</td>\n<td>0.4283187</td>\n<td>0.0049410</td>\n<td>0.4318581</td>\n<td>0.4218883</td>\n<td>0.4306012</td>\n<td>0.4242424</td>\n<td>0.4330036</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-16.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-16 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-16 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-16 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-16 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-16 .h2o-table th,\n#h2o-table-16 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-16 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-16\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>iteration</th>\n<th>lambda</th>\n<th>predictors</th>\n<th>deviance_train</th>\n<th>deviance_xval</th>\n<th>deviance_se</th>\n<th>alpha</th>\n<th>iterations</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_r2</th>\n<th>training_classification_error</th>\n<th>training_auc</th>\n<th>training_pr_auc</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.000 sec</td>\n<td>5</td>\n<td>.22E2</td>\n<td>8430</td>\n<td>2.2481407</td>\n<td>5.1499317</td>\n<td>2.8347244</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:00</td>\n<td> 0.677 sec</td>\n<td>8</td>\n<td>.16E2</td>\n<td>8430</td>\n<td>2.1535965</td>\n<td>5.0728719</td>\n<td>2.8539896</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:01</td>\n<td> 1.367 sec</td>\n<td>12</td>\n<td>.12E2</td>\n<td>8430</td>\n<td>2.0629104</td>\n<td>2.1267346</td>\n<td>0.0030129</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:02</td>\n<td> 2.145 sec</td>\n<td>16</td>\n<td>.84E1</td>\n<td>8430</td>\n<td>1.9758454</td>\n<td>2.0371638</td>\n<td>0.0034498</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:03</td>\n<td> 3.117 sec</td>\n<td>21</td>\n<td>.61E1</td>\n<td>8430</td>\n<td>1.8925664</td>\n<td>1.9516813</td>\n<td>0.0039380</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:04</td>\n<td> 4.269 sec</td>\n<td>26</td>\n<td>.44E1</td>\n<td>8430</td>\n<td>1.8151123</td>\n<td>1.8703870</td>\n<td>0.0043125</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:05</td>\n<td> 5.408 sec</td>\n<td>32</td>\n<td>.32E1</td>\n<td>8430</td>\n<td>1.7426295</td>\n<td>1.7921156</td>\n<td>0.0049156</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:06</td>\n<td> 6.448 sec</td>\n<td>38</td>\n<td>.24E1</td>\n<td>8430</td>\n<td>1.6742461</td>\n<td>1.7223635</td>\n<td>0.0053823</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:07</td>\n<td> 7.583 sec</td>\n<td>44</td>\n<td>.17E1</td>\n<td>8430</td>\n<td>1.6059456</td>\n<td>1.6532299</td>\n<td>0.0055496</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:08</td>\n<td> 8.727 sec</td>\n<td>50</td>\n<td>.12E1</td>\n<td>8430</td>\n<td>1.5466921</td>\n<td>1.5902173</td>\n<td>0.0069976</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.010 sec</td>\n<td>171</td>\n<td>.38E-1</td>\n<td>8430</td>\n<td>1.2047304</td>\n<td>1.2193720</td>\n<td>0.0117154</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:32</td>\n<td>32.307 sec</td>\n<td>172</td>\n<td>.28E-1</td>\n<td>8430</td>\n<td>1.2045840</td>\n<td>1.2145365</td>\n<td>0.0109515</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.306 sec</td>\n<td>201</td>\n<td>.2E-1</td>\n<td>8430</td>\n<td>1.1701560</td>\n<td>1.2028763</td>\n<td>0.0073754</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:38</td>\n<td>38.682 sec</td>\n<td>203</td>\n<td>.15E-1</td>\n<td>8430</td>\n<td>1.1698354</td>\n<td>1.1946579</td>\n<td>0.0072719</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>38.964 sec</td>\n<td>204</td>\n<td>.11E-1</td>\n<td>8430</td>\n<td>1.1697613</td>\n<td>1.1861467</td>\n<td>0.0142486</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.151 sec</td>\n<td>205</td>\n<td>.77E-2</td>\n<td>8430</td>\n<td>1.1696958</td>\n<td>1.1762901</td>\n<td>0.0134454</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.433 sec</td>\n<td>206</td>\n<td>.56E-2</td>\n<td>8430</td>\n<td>1.1696321</td>\n<td>1.1763251</td>\n<td>0.0134399</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.627 sec</td>\n<td>207</td>\n<td>.41E-2</td>\n<td>8430</td>\n<td>1.1695628</td>\n<td>1.5288045</td>\n<td>0.3599716</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:39</td>\n<td>39.917 sec</td>\n<td>208</td>\n<td>.3E-2</td>\n<td>8430</td>\n<td>1.1694942</td>\n<td>1.7391552</td>\n<td>0.2422446</td>\n<td>0.0</td>\n<td>None</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td></tr>\n<tr><td></td>\n<td>2023-09-09 00:44:40</td>\n<td>40.108 sec</td>\n<td>209</td>\n<td>.22E-2</td>\n<td>8430</td>\n<td>1.1694213</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>209</td>\n<td>0.4280755</td>\n<td>0.5848479</td>\n<td>0.9391927</td>\n<td>0.2094498</td>\n<td>nan</td>\n<td>nan</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[30 rows x 17 columns]</pre></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-17.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-17 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-17 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-17 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-17 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-17 .h2o-table th,\n#h2o-table-17 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-17 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-17\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>col874</td>\n<td>0.2500748</td>\n<td>1.0</td>\n<td>0.0024913</td></tr>\n<tr><td>col919</td>\n<td>0.2400129</td>\n<td>0.9597644</td>\n<td>0.0023910</td></tr>\n<tr><td>col166</td>\n<td>0.2380715</td>\n<td>0.9520010</td>\n<td>0.0023717</td></tr>\n<tr><td>col862</td>\n<td>0.2356163</td>\n<td>0.9421830</td>\n<td>0.0023472</td></tr>\n<tr><td>col44</td>\n<td>0.2344190</td>\n<td>0.9373954</td>\n<td>0.0023353</td></tr>\n<tr><td>col196</td>\n<td>0.2310739</td>\n<td>0.9240192</td>\n<td>0.0023020</td></tr>\n<tr><td>col877</td>\n<td>0.2308466</td>\n<td>0.9231103</td>\n<td>0.0022997</td></tr>\n<tr><td>col322</td>\n<td>0.2257164</td>\n<td>0.9025955</td>\n<td>0.0022486</td></tr>\n<tr><td>col925</td>\n<td>0.2199686</td>\n<td>0.8796110</td>\n<td>0.0021913</td></tr>\n<tr><td>col184</td>\n<td>0.2173196</td>\n<td>0.8690182</td>\n<td>0.0021650</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>col0</td>\n<td>0.0118955</td>\n<td>0.0475679</td>\n<td>0.0001185</td></tr>\n<tr><td>col392</td>\n<td>0.0116441</td>\n<td>0.0465625</td>\n<td>0.0001160</td></tr>\n<tr><td>col36</td>\n<td>0.0114414</td>\n<td>0.0457518</td>\n<td>0.0001140</td></tr>\n<tr><td>col98</td>\n<td>0.0108436</td>\n<td>0.0433615</td>\n<td>0.0001080</td></tr>\n<tr><td>col740</td>\n<td>0.0107983</td>\n<td>0.0431803</td>\n<td>0.0001076</td></tr>\n<tr><td>col788</td>\n<td>0.0101019</td>\n<td>0.0403954</td>\n<td>0.0001006</td></tr>\n<tr><td>col92</td>\n<td>0.0100254</td>\n<td>0.0400895</td>\n<td>0.0000999</td></tr>\n<tr><td>col39</td>\n<td>0.0097240</td>\n<td>0.0388845</td>\n<td>0.0000969</td></tr>\n<tr><td>col743</td>\n<td>0.0078202</td>\n<td>0.0312714</td>\n<td>0.0000779</td></tr>\n<tr><td>col1298</td>\n<td>0.0073290</td>\n<td>0.0293072</td>\n<td>0.0000730</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[1404 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.load_model('/home/vorkov/Workspace/Emotion-Decetion-Service/learning/GLM_1_AutoML_1_20230909_00442')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T23:11:28.538100331Z",
     "start_time": "2023-09-08T23:11:28.417201700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
